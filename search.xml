<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[Building a GNU-Autotools-based Project for iOS: Part 1]]></title>
      <url>%2F2019%2F10%2F17%2FBuild-a-GNU-Autotools-based-project-for-iOS-Part-1%2F</url>
      <content type="text"><![CDATA[The open-source movement started in the middle of the Desktop domination, which could explain why there are much fewer resources in the mobile wild.Recently I tried to build a few renowned C/C++ open-source projects for iOS, only to find that: Nothing works out of the box; The scattered info on the Internet is often inconsistent or out of date. … familiar pattern for a platform with breaking changes every so often, keeping everyone busy and unable to document things tightly. But here is my $0.02. Hope it’ll help me and someone who got bruises out of trials-and-errors. In Part 1, I’ll focus on how I managed to build static libs for iOS. EnvironmentCheck my setup before getting excited. You know why, having tried and failed upon many StackOverflow tips. macOS 10.14.6 iOS 13.1 Xcode 11.1 If you can’t get my solution working for your own projects, e.g., when it’s based on a more recent environment, it’s quite possible that you need a next-gen tip. The Working SolutionFor the impatient, here is the build script to place in the root folder of your autotool-based project 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879#! /bin/sh## Build for iOS 64bit-ARM variants and iOS Simulator# - Place the script at project root# - Customize MIN_IOS_VERSION and other flags as needed# # Test Environment# - macOS 10.14.6# - iOS 13.1# - Xcode 11.1#Build() &#123; # Ensure -fembed-bitcode builds, as workaround for libtool macOS bug export MACOSX_DEPLOYMENT_TARGET="10.4" # Get the correct toolchain for target platforms export CC=$(xcrun --find --sdk "$&#123;SDK&#125;" clang) export CXX=$(xcrun --find --sdk "$&#123;SDK&#125;" clang++) export CPP=$(xcrun --find --sdk "$&#123;SDK&#125;" cpp) export CFLAGS="$&#123;HOST_FLAGS&#125; $&#123;OPT_FLAGS&#125;" export CXXFLAGS="$&#123;HOST_FLAGS&#125; $&#123;OPT_FLAGS&#125;" export LDFLAGS="$&#123;HOST_FLAGS&#125;" EXEC_PREFIX="$&#123;PLATFORMS&#125;/$&#123;PLATFORM&#125;" ./configure \ --host="$&#123;CHOST&#125;" \ --prefix="$&#123;PREFIX&#125;" \ --exec-prefix="$&#123;EXEC_PREFIX&#125;" \ --enable-static \ --disable-shared # Avoid Xcode loading dylibs even when staticlibs exist make clean mkdir -p "$&#123;PLATFORMS&#125;" &amp;&gt; /dev/null make V=1 -j"$&#123;MAKE_JOBS&#125;" --debug=j make install&#125;echo "HI"# LocationsScriptDir="$( cd "$( dirname "$0" )" &amp;&amp; pwd )"cd - &amp;&gt; /dev/nullPREFIX="$&#123;ScriptDir&#125;"/_buildPLATFORMS="$&#123;PREFIX&#125;"/platformsUNIVERSAL="$&#123;PREFIX&#125;"/universal# Compiler optionsOPT_FLAGS="-O3 -g3 -fembed-bitcode"MAKE_JOBS=8MIN_IOS_VERSION=8.0# Build for platformsSDK="iphoneos"PLATFORM="arm"PLATFORM_ARM=$&#123;PLATFORM&#125;ARCH_FLAGS="-arch arm64 -arch arm64e" # -arch armv7 -arch armv7sHOST_FLAGS="$&#123;ARCH_FLAGS&#125; -miphoneos-version-min=$&#123;MIN_IOS_VERSION&#125; -isysroot $(xcrun --sdk $&#123;SDK&#125; --show-sdk-path)"CHOST="arm-apple-darwin"BuildSDK="iphonesimulator"PLATFORM="x86_64-sim"PLATFORM_ISIM=$&#123;PLATFORM&#125;ARCH_FLAGS="-arch x86_64"HOST_FLAGS="$&#123;ARCH_FLAGS&#125; -mios-simulator-version-min=$&#123;MIN_IOS_VERSION&#125; -isysroot $(xcrun --sdk $&#123;SDK&#125; --show-sdk-path)"CHOST="x86_64-apple-darwin"Build# Create universal binarycd "$&#123;PLATFORMS&#125;/$&#123;PLATFORM_ARM&#125;/lib"LIB_NAME=`find . -iname *.a`cd -mkdir -p "$&#123;UNIVERSAL&#125;" &amp;&gt; /dev/nulllipo -create -output "$&#123;UNIVERSAL&#125;/$&#123;LIB_NAME&#125;" "$&#123;PLATFORMS&#125;/$&#123;PLATFORM_ARM&#125;/lib/$&#123;LIB_NAME&#125;" "$&#123;PLATFORMS&#125;/$&#123;PLATFORM_ISIM&#125;/lib/$&#123;LIB_NAME&#125;"echo "BYE" The Expected ResultsAssuming you are at the project root, run the script and you should get: The static libs for arm64 family and iOS simulator under ./\_build/platforms/&lt;ARCH&gt;/lib The universal binary for all architectures combined Running a lipo check on the universal binary should give you something like these: 12$ lipo -info /path/to/mylib/_build/arm/lib/libmylib.aArchitectures in the fat file: /path/to/mylib/_build/arm/lib/libmylib.a are: arm64 arm64e 12$ lipo -info /path/to/mylib/_build/x86_64-sim/lib/libmylib.aNon-fat file: /path/to/mylib/_build/x86_64-sim/lib/libmylib.a is architecture: x86_64 12$ lipo -info /path/to/mylib/_build/universal/libmylib.aArchitectures in the fat file: /path/to/mylib/_build/universal/libmylib.a are: x86_64 arm64 arm64e The Lessons LearnedI feel obliged to write down the major gotchas that may be help in the future Compiler ExecutablesI lost most of my time to this. I started by using the autotools compiler environment variables this way: 1CC=clang I then always ended up with x86_64 instead of arm64 as my arm builds. The correct way is shown in the solution. Before getting there, I was on the wrong track of distrusting the architecture triplets that I copied from the Internet. I’ve tried numerous triplets, i.e., arch-vendor-os, to no avail. GNU is not famous on giving you a list of standard names that just work. The closest lists I could find are: Libtool platforms LLVM’s llvm::Triple Class It proved that none of them help with my situation. To make it worse, config.guess always gives me the wrong x86_64 as well: 12$ ./config.guessx86_64-apple-darwin18.7.0 Knowing that autotools is just a wrapper over the real compilers, I’ve also tried to understand how the compiler works behind autotools. I created an Xcode project and watched the IDE build log, hunting for clues on magic flags. This proved useless as well, including the intriguing clang flag -target arm64-apple-ios13.1, not to be confused with the --target flag for configure. The cross-compile idea also made me tweak the build/host/target combination over and over, only to find that having --host alone will suffice, the rest is implied by the assigned toolchain variables and flags. BitcodeSince iOS 9, enabling bitcode is required for library providers. However, to enabling bitcode without causing compiler errors such as: 1ld: -bind_at_load and -bitcode_bundle (Xcode setting ENABLE_BITCODE=YES) cannot be used together I have to put in a trick to signify the build machine version, which works around a supposed libtool bug: 1export MACOSX_DEPLOYMENT_TARGET="10.4" Shared libsWithout adding --disabled-shared, autotools generate both dynamic and static libs for the project. This turns out to cue Xcode to try to load shared libs first (CRASH) even when I have not specified -l for the dylibs. So --disabled-shared is mandatory for using static libs. ConclusionsAutotools-based open-source projects have a long history from Desktop ages. Although the new build systems like CMakes improve the cross-platform build environment, the mobile devs inevitably bump into dinosaur autotools-based repos, rigged with traps. Patience in research is the only cure, IMHO. In Part 2 (schedule TBD), I’ll build a Framework for iOS using autotools. References bitcode Compiler Executables Cross-compile for ARM with Autoconf Shared Libs]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[十条你得知道的 Wwise Launcher 用法（2019 版）]]></title>
      <url>%2F2019%2F07%2F08%2F%E4%BD%A0%E5%BE%97%E7%9F%A5%E9%81%93%E7%9A%84-Wwise-Launcher%2F</url>
      <content type="text"><![CDATA[注：本文基于 2018 年初在 Audiokinetic 公众号上发表的文章《十一条你可能不知道的 Wwise Launcher 用法》，由作者针对软件更新做了改动，不影响操作的截图沿用旧版本。 本文基于以下环境 Wwise Launcher: 2019.5.0.905 Wwise: 2019.1.0.6947 macOS Mojave 10.14.5 从 2016 年起，你在 Audiokinetic 官网点击下载 Wwise 的时候，实际上下载的是 Wwise Launcher（下文简称 Launcher），后来你就习惯用 Launcher 来下载更新 Wwise 了。你还学会了用它管理本机上的多个工程和 Wwise 版本，对吧？但对新手，Launcher 可能还有不明显的功能和注意事项对你会很有用，本文初版一年多后，我们再来梳理一下吧！ 1. Wwise Launcher 有权威参考资料吗？如今我们有了详细的官方图文文档，可从 Launcher 的？页菜单项`Wwise Launcher Documentation直达，本文中的许多内容已可在文档中找到。不过在本文写作时，文档只有英文版，零星信息尚未与最新软件版本同步，因此下文还会给出必要的向导。英文自信的同学扫读本文即可。 2. 程序员：哪里有 Wwise 集成／整合方面的例程？我们可以通过 Launcher 来安装 Wwise 的IntegrationDemo。如果我们已经安装了 Wwise，但是没有找到这个 Demo，则需要打开 Launcher，找到WWISE页上我们的目标版本，然后修改安装。 勾选左边选项框中的SDK (C++)，和右边的目标平台。 之后点击Install...开始安装。安装结束后切换到SAMPLES页，选中正确的 Wwise 版本（图中为2017.1.4），便可以看到IntegrationDemo了。 如果想运行 Demo，则直接点击Run IntegrationDemo；如果想打开对应的 Wwise 工程检查或修改声音设计内容，那么点击Open in Wwise。 如果想打开源码工程，则点击左边按钮的下拉菜单，之后打开 Demo 所在文件夹， 通过文件系统打开对应平台的子文件夹，找到并打开 IDE 工程文件。 在研究 IntegrationDemo 的时候，推荐对照Wwise SDK Help文档来学习，特别是声音引擎集成纵览一节。 不论我们的项目用的是自研引擎还是商业引擎，IntegrationDemo都是我们学习 Wwise 整合代码最好的帮手。这是因为IntegrationDemo是 Wwise SDK 的一部分，Audiokinetic 会持续维护测试这组例程和对应的 Wwise 工程；每当有重要的新功能时，该 Demo 中一般会加入新功能演示。 更重要的是，假如我们的项目出现了奇怪的问题，开始怀疑是不是 Wwise 的 bug 时，可以首先尝试用 IntegrationDemo 来对照重现问题，Demo 提供的简化环境经过了反复测试，有助于隔离发现应用端的整合问题。Demo 中重现不了的问题往往会暴露出用户端的使用不当。 2. 我们公司大部分机器在内网，怎么安装 Wwise？我们可以用某台外网机安装需要的 Wwise 组件，然后通过 Launcher 制作离线安装包给内网机使用： 添加插件为单独步骤，在制作离线包时注意勾选所有需要的插件。 做好的离线包除了组件文件夹bundle外，会自带一个配套的 Launcher 安装包： 最后将离线安装包发送到各台内网机上，在内网机上分别装好包里自带的 Launcher，再打开 Launcher 定位到离线包来安装。 注意：Windows 版的 Launcher 只能安装 Windows 版的设计工具，Mac 版类似。 3. 我下载安装了 Wwise，但是我的工程在生成 SoundBank 时报错，说最多只能使用 200 个声音文件，怎么办？这说明我们的工程没有添加合适的 Wwise 授权码。我们需要打开 Launcher，登录我们的 Audiokinetic 账号，在PROJECTS页找到我们的 Wwise 工程，点击钥匙状按钮，接着我们有两个选择： 1）注册新项目，并等待 Audiokinetic 商务联系人批准项目注册并接收系统邮件取得授权码。 这时我们会来到官网项目注册页面，需要根据向导填好所有信息并提交申请。之后如果确信申请通过了但没有收到系统邮件，则最好检查一下垃圾邮箱。 2）如果我们的项目确定已经注册了，只是没有导入授权码，则需要注意：每个 Wwise 项目在 Audiokinetic 官网上都有若干管理员（Wwise Project Leader)，他们一般是我们自己项目团队的成员。可以联系管理员把我们的 Audiokinetic 账号加入该项目，之后便可以在 Launcher 里工程的Set Project License菜单中找到对应的项目授权码并授权项目了，做授权码导入操作时要确保关闭已经打开的工程。 4. 如何安装 Unity 集成？假设我们的电脑上已经装了 Unity，并且创建了 Unity 工程，而我们现在想给其中某个 Unity 工程安装 Wwise 集成。这时我们需要来到 Launcher 的UNITY页，点开顶部菜单的浏览按钮： 选中目标 Unity 工程并确认后，在UNITY页的工程列表里就能看到这个工程了。接下来我们有两个选择： 1）直接从官网下载 Unity 集成并同时安装， 2）先下载离线安装包， 然后通过 Launcher 手动安装。 注意，无论用哪种方法，安装期间必须关闭所有打开的 Unity 编辑器。如果需要定制 Unity 集成，可以在离线安装包中解压出源码包，再重新编译 Unity 集成。 Unreal Engine 的安装方法与此类似，在UNREAL ENGINE页中完成。 5. 新手怎么学习 Unity 和 Unreal Engine 集成？学习 Unity 集成有两个选择： 1）通过 Launcher 安装运行 Unity 集成示例，再对照官方文档学习。 2）通过官方免费的认证课程系列 中的 Wwise-301 （以及 Wwise-251 中的一部分）学习，对 Wwise 新手而言这一般意味着你要先学习入门课程 Wwise-101，但可能很多过来人都会告诉你，这是值得的，别问我为什么知道 ^_* 学习 Unreal 集成， 我们也有两个选择： 1）通过 Launcher 的UNREAL ENGINE页安装运行 Unreal 集成示例，再对照官方文档学习。 2）通过 Launcher 安装运行 Wwise 的空间音频 Demo：Wwise Audio Lab 6. 我网速慢，看在线文档不方便，如何在本地查看 Wwise 的音频设计和程序整合文档？我们可以通过 Launcher 安装离线文档，注意要选择想要的平台。 之后就可以在WWISE页的对应 Wwise 版本下找到各个平台对应的多语言离线文档了。 容易忽略的是：Unity 和 Unreal Engine 集成的离线包中自带了离线文档（.chm 和.html包），解包时不要错过哦～ 7.我感觉碰到了一个 Wwise 的 Bug，该怎么上报？我们可以去?页的About，点击Report a Bug...，接着根据向导提供必要信息确认上传即可，支持上传截图、Wwise 工程 zip 包和普通 zip 包。汇报成功后，你会看到类似下图的截图，别问我怎么知道的 :P 8. Launcher 在安装中出现错误或者操作失败怎么办？我们可以去?页的About Wwise Launcher...， 找到 Launcher 的完整日志， 然后想办法汇报给 Audiokinetic 的项目技术支持或社区问答论坛，或者如果你确信是 Bug，参见上一条。 最常见的问题是网络问题，出这类问题的时候如果开了 VPN，则可以尝试关闭了 VPN 再使用 Launcher。 有一类特殊问题是通过 Launcher 安装和升级 Unity 集成的时候失败了，这时怎么办呢？ 首先我们需要根据Unity 集成版本说明来确认要安装的 Wwise 版本对应支持的 Unity 版本。 如果版本都是对的，则需要打开 Unity 编辑器观察控制台里的错误信息。Wwise Unity 集成安装时需要运行 Unity 程序来做一些初始化或者升级工作，这个过程中 Unity 工程内部可能错误，但这些错误并不会在 Launcher 界面上显示出来，要在 Unity 编辑器中查看。 9. 向 Wwise 工作人员提技术问题时，怎样让沟通更准确高效？我们在项目档期紧张时遇到 Wwise 相关的技术问题，常常撒腿就找官方技术支持。但是巧妇难为无米之炊，没有客观详实的诊断信息，支持人员也只能来回提问试探，沟通效率可能会不理想。为了高效沟通，我们可以善用 Wwise 的 Profiler（性能分析器）来记录问题过程，利用 Launcher 来制作诊断包，在提问时将诊断包发送给官方技术支持。 Windows 版本的 Launcher 整合了 Wwise 中的辅助工具Wwise Project Zipper的功能，支持 Windows 和 macOS。 可以将 Wwise 工程及性能分析器日志记录 （profiler session）定制内容后打包。 之后便可以前往官网项目的技术支持频道将 zip 包作为附件发送给 Audiokinetic 的技术支持了。这样的做法通常可以为我们省去好几轮前期沟通。 10. 怎样了解 Audiokinetic 的新闻和最新技术？我们打开 Launcher 的首页，便可以看到最新的 Audiokinetic 的英文版新闻和技术博客。 首页上还有社区问答论坛的最新提问，可以从中学习其他用户的经验。 如果要看中文版，现在可以直接点击 Launcher 首页右上角的语言列表切换。 后记越来越多的集成开发环境包括 Unity 和 Unreal Engine 利用独立于编辑器的 Launcher（启动器）作为控制中心程序来管理工程和资源。这样做，一来可以方便用户管理多个引擎版本和工程，避免和操作系统文件管理器中铺天盖地的文件夹和文件类型缠斗，甚至发生零散文件操作引起的意外；二来可以整合引擎开发商提供的一系列服务。在 Wwise 工作流程中，Wwise Launcher 正在扮演类似的角色，并且还在成长中。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[为什么我听不到声音？]]></title>
      <url>%2F2018%2F02%2F04%2Fwhy-cant-i-hear-my-sound%2F</url>
      <content type="text"><![CDATA[本文基于以下软件版本： Wwise Launcher: 2018.1.24.738 Wwise: 2017.1.4.640 macOS Sierra 10.12.6 (16G1212) hello!]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[十条你可能不知道的 Wwise Launcher 用法]]></title>
      <url>%2F2018%2F01%2F04%2F%E4%BD%A0%E6%89%80%E4%B8%8D%E7%9F%A5%E9%81%93%E7%9A%84-Wwise-Launcher%2F</url>
      <content type="text"><![CDATA[本文基于以下软件版本： Wwise Launcher: 2017.11.30.720 Wwise: 2017.1.4.6407 macOS Sierra 10.12.6 (16G1114) 从 2016 年起，在 Audiokinetic 官网点击下载 Wwise 的时候，你实际上下载的是 Wwise Launcher（下文简称 Launcher），到现在你应该已经习惯用 Launcher 来下载更新 Wwise 本身甚至管理本机上的多个工程和 Wwise 版本了，但 Launcher 可能还有一些不太明显的功能和注意事项对你会很有用，我们今天就来梳理一下吧！ 1. 程序员：哪里有 Wwise 集成／整合方面的例程？ 我们可以通过 Launcher 来安装 Wwise 的IntegrationDemo。如果我们已经安装了 Wwise，但是没有找到这个 Demo，则需要打开 Launcher，找到WWISE页上我们的目标版本，然后修改安装。 勾选左边选项框中的SDK (C++)，和右边的目标平台。 之后点击Install...开始安装。安装结束后切换到SAMPLES页，选中正确的 Wwise 版本（图中为2017.1.4），便可以看到IntegrationDemo了。 如果想运行 Demo，则直接点击Run IntegrationDemo；如果想打开对应的 Wwise 工程检查或修改声音设计内容，那么点击Open in Wwise。 如果想打开源码工程，则点击左边按钮的下拉菜单，之后打开 Demo 所在文件夹， 通过文件系统打开对应平台的子文件夹，找到并打开 IDE 工程文件。 在研究 IntegrationDemo 的时候，推荐对照Wwise SDK Help文档来学习，特别是声音引擎集成纵览一节。 因为IntegrationDemo是 Wwise SDK 的一部分，Audiokinetic 会持续维护测试这组例程和对应的 Wwise 工程；每当有重要的新功能时，该 Demo 中一般会加入新功能演示，所以不论我们的项目用的是自研引擎还是商业引擎比如 Unity／Cocos2d-x，IntegrationDemo都是我们学习 Wwise 整合代码最好的帮手。 更重要的是，假如我们的项目出现了奇怪的问题，开始怀疑是不是 Wwise 的 bug 时，可以首先尝试用 IntegrationDemo 来对照重现问题，Demo 提供的是高度简化和反复测试过的环境，有助于隔离发现应用端的整合问题。Demo 中重现不了的问题最终往往会证明来自应用端的使用不当。 2. 我们公司大部分机器在内网，怎么安装 Wwise？ 我们可以用某台外网机安装需要的 Wwise 组件，然后通过 Launcher 制作离线安装包给内网机使用： 做好的离线包除了组件文件夹bundle外，会自带一个配套的 Launcher 安装包： 最后将离线安装包发送到各台内网机上，在内网机上分别装好包里自带的 Launcher，再打开 Launcher 定位到离线包来安装。 3. 我下载安装了 Wwise，但是我的工程在生成 SoundBank 时报错，说最多只能使用 200 个声音文件，怎么办？ 这说明我们的工程没有添加合适的 Wwise 授权码。我们需要打开 Launcher，登录我们的 Audiokinetic 账号，在PROJECTS页找到我们的 Wwise 工程，点击钥匙状按钮，这时我们有两个选择：1）注册新项目，并等待 Audiokinetic 商务联系人批准项目注册并接收系统邮件取得授权码。 这时我们会来到官网项目注册页面，需要根据向导填好所有信息并提交申请。之后如果确信申请通过了但没有收到系统邮件，则最好检查一下垃圾邮箱。 2）如果我们的项目确定已经注册了，只是没有导入授权码，则需要注意：每个 Wwise 项目在 Audiokinetic 官网上都有若干管理员（Wwise Project Leader)，他们一般是我们自己项目团队的成员。可以联系管理员把我们的 Audiokinetic 账号加入该项目，之后便可以在 Launcher 里工程的Set Project License菜单中找到对应的项目授权码并授权项目了，做授权码导入操作时要确保关闭已经打开的工程。 4. 如何安装 Unity 集成？ 假设我们的电脑上已经装了 Unity，并且创建了 Unity 工程，而我们现在想给其中某个 Unity 工程安装 Wwise 集成。这时我们需要来到 Launcher 的UNITY页，点开顶部菜单的浏览按钮： 选中目标 Unity 工程并确认后，在UNITY页的工程列表里就能看到这个工程了。接下来我们有两个选择：1）直接从官网下载 Unity 集成并同时安装， 或者 2）先下载离线安装包， 然后通过 Launcher 手动安装。 注意，无论用哪种方法，安装期间必须关闭所有打开的 Unity 编辑器。 5. 新手怎么学习 Wwise Unity 和 Unreal Engine 集成？ 学习 Unity 集成可以通过 Launcher 安装运行 Unity 集成示例，再对照官方文档学习。 学习 Unreal 集成， 我们有两个选择：1）可以通过 Launcher 的UNREAL ENGINE页安装运行 Unreal 集成示例，再对照官方文档学习。 2）也可以通过 Launcher 安装运行 Wwise 的空间音频 Demo：Wwise Audio Lab 6. 我需要根据特定 Wwise SDK 库版本来重新编译 Wwise Unity 集成，怎么办？ 有时候我们等不及官方 Unity 集成补丁，而想基于某个已经下载好的原生 SDK 补丁库来重新构建 Unity 集成， 这时我们需要的是 Unity 集成的源码包，可以在 Launcher 的UNITY页下载离线安装包来取得（见4. 如何安装 Unity 集成？）。 离线包的格式为 .tar.xz，一般我们需要通过 Launcher 安装集成来解出源码包来。如果想手动解包，则需要安装可以解压XZ和TAR格式的程序。比如在 macOS 上，我们可以通过Homebrew来安装xz这个包，之后即可通过命令行xz -d 来解包了。源码包的文件一般以_Src.zip结尾。 重新编译 Unity 集成的方法见官方文档。 7. 我网速慢，看在线文档不方便，如何在本地查看 Wwise 的音频设计和程序整合文档？ 我们可以通过 Launcher 安装离线文档，注意要选择想要的平台。 之后就可以在WWISE页的对应 Wwise 版本下找到各个平台对应的多语言离线文档了。 8. Launcher 在安装中出现错误或者操作失败怎么办？ 我们可以去?页的About， 找到 Launcher 的完整日志， 然后想办法汇报给 Audiokinetic 的项目技术支持或社区问答论坛。 最常见的问题是网络问题，出这类问题的时候如果开了 VPN，则可以尝试关闭了 VPN 再使用 Launcher。 有一类特殊问题是通过 Launcher 安装和升级 Unity 集成的时候失败了，这时怎么办呢？ 首先我们需要根据Unity 集成版本说明来确认要安装的 Wwise 版本对应支持的 Unity 版本。 如果版本都是对的，则需要打开 Unity 编辑器观察控制台里的错误信息。Wwise Unity 集成安装时需要运行 Unity 程序来做一些初始化或者升级工作，这个过程中 Unity 工程内部可能错误，但这些错误并不会在 Launcher 界面上显示出来，要在 Unity 编辑器中查看。 9. 提出技术支持问题时，怎样让沟通更准确高效？ 我们在项目档期紧张时遇到 Wwise 相关的技术问题，首先想到的是请求官方技术支持支援。但是巧妇难为无米之炊，没有客观详实的诊断信息，支持人员也只能来回提问试探，沟通效率可能会不理想。为了提高沟通效率，我们可以善用 Wwise 的 Profiler（性能分析器）来记录问题过程，利用 Launcher 来制作诊断包，在提问时将诊断包发送给官方技术支持。 Windows 版本的 Launcher 整合了 Wwise 中的辅助工具Wwise Project Zipper的功能（macOS 版暂时没有此功能）， 可以将 Wwise 工程及性能分析器日志记录 （profiler session）定制内容后打包。 之后便可以前往官网项目的技术支持频道将 zip 包作为附件发送给 Audiokinetic 的技术支持了。这样的做法通常可以为我们省去好几轮前期沟通。 10. 怎样了解 Audiokinetic 的新闻和最新技术？ 我们打开 Launcher 的首页，便可以看到最新的 Audiokinetic 的英文版新闻和技术博客。 首页上还有社区问答论坛的最新提问，可以从中学习其他用户的经验。 如果要看中文版，目前可以先点击 Launcher 首页任何链接来到 Audiokinetic 官网，然后切换语言为简体中文。 后记 越来越多的集成开发环境包括 Unity 和 Unreal Engine 利用独立于编辑器的 Launcher（启动器）作为控制中心程序来管理工程和资源。这样做，一来可以方便用户管理多个引擎版本和工程，避免和操作系统文件管理器中铺天盖地的文件夹和文件类型缠斗，甚至发生零散文件操作引起的意外；二来可以整合引擎开发商提供的一系列服务。在 Wwise 工作流程中，Wwise Launcher 正在扮演类似的角色，并且还在成长中。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[快速试听 Wwise 互动音乐的过渡]]></title>
      <url>%2F2017%2F10%2F29%2Fquick-auditioning-music-transitions%2F</url>
      <content type="text"><![CDATA[本文探讨的所有问题和解决方案都基于 Wwise 2017.1.x。不对后续版本负责。 起因：听一下过渡好难利用 Wwise 的互动音乐功能可以用小段音乐编组搭建出动态和互动的曲式和织体，但搭完了之后你还是得用耳朵试听乐段间的过渡，确保衔接在音乐意义上是无缝的。截至 Wwise 2017.1，不少人在这里遇到了麻烦，见下图： 这个例子来自 Wwise 自带的示例工程Sample Project（可以从Wwise Launcher 的SAMPLES页下打开），在 Music Playlist Editor 中，Stealth这个 Music Playlist Container 中有一个 Sequence Continuous 模式的 Music Segment 编组，图中正在试听前两个 Music Segment 间的过渡。这时，由于Stealth采用的过渡规则中，Source 段用了Exit source at Exit Cue这条同步规则，见下图： Exit Cue 一般靠近曲子尾声，所以你必须把Stealth_Seg_01从头听到 Exit Cue 处才能开始试听和Stealth_Seg_02间的过渡，如果曲子很长，这样就很浪费时间；还有更惨的：当要听的过渡在一个很长的连续列表的中间靠后时，即便同步点是 Next Bar 这样近距离的，每次你还都得从最顶上听起。如下图： 要听Seg 02b (B)到下一段的过渡时，你每次都得从Seg 01a (A)听起。上图里还比较仁慈，每个段落都只循环了一次，万一有些会循环有限次，万一播着中间接了个电话，… 你懂的。 于是你又下意识地跑到 Music Segment Editor 界面中想对着波形迅速定位到过渡点附近听，结果发现一次又只能试听一个 Segment，见下图： 所以还是快不起来。 在别的情况下，也会有类似问题： 确认单个 Music Segment 的循环无缝时。 试听 Music Switch Container 下的状态切换时。 需要强调的是，麻烦大小和设计有关，短小的 Music Segment 可能几乎感觉不到。 面对这些情况，你的需求大概是这么三条： 能从播放列表中直接挑出任何一对 Music Segment 来听过渡，不管它们在什么地方。 能定位到过渡点附近开始听。 能试听单曲循环的首尾衔接。 换句话说：如今主流媒体播放器能做到的一些事情。 上图中，如果你想听Say和Architect这两首曲子间的过渡（假设有的话），那么只需要鼠标双击Say这首，然后用底部进度条定位到尾部收听即可。如果要测自循环，则只需要把循环模式调到单曲循环就行了（注：Wwise 中由于有同步点的问题，常规的进度条还不够）。 相比之下，我们发现：Wwise 虽然提供了搭建非线性音乐结构的一整套工具，但其 UI 的预览功能不支持线性媒体播放器中的列表定点播放体验。 当然，反过来大多数线性媒体播放器也不支持 Wwise 提供的众多非线性播放功能。 在 Wwise 在 UI 上做出改进之前，我们暂时还得面对这个问题。 好消息是，“解决方法“（Hack）还是有的，虽然都不完美！我们来看看到 Wwise 2017.1 版本为止，目前已知的三种方法。我把它们按从直观到抽象排了序。 方法一：手动拼接法看到标题你估计已经有点失望了。没错，这个方法很简单粗暴：通过复制粘贴把想要一起听过渡的几个 Clip 放到 Music Segment Editor 的多轨界面上，手动确保各个 Clip 的 Exit Cue 和 Entry Cue 彼此对齐，最后通过光标直接定位到过渡点附近收听播放。如果要测某一轨的无缝循环，那就把该轨上的内容复制一遍紧贴在自己的尾巴上。 实际操作中有个麻烦：在 Music Segment Editor 下对齐来自两个 Music Segment 的 Clip 时，只有一个 Segment 的 Exit Cue 和 Entry Cue 能显示出来，另一个的则看不到。所以你可能要另想办法来对齐同步点，比如用 Clip handle 临时裁剪掉看不到 cue 的 Music Segment 的 Pre-Entry 或者 Post-Exit 部分，不然很难肉眼对齐。 这个方法的优点是： 概念简单，接近 DAW 里面的操作习惯。 能通过交互来精确定位到过渡点附近。 可以试听任何 Music Segment 甚至单个 Clip 的组合。 但缺点很明显： 用来拼接 Music Segment 的临时操作会改动 Music Segment，污染了设计本身。事后还得清理现场。虽然可以创建专门的“测试段落”，但就要维护这个多轨测试对象，并不轻松。 很难快速测试多轨 Music Segment 间的过渡。上面说的 Clip handle 操作对各轨可能都要做一遍。 手动操作繁琐，对齐容易出错。 这个方法大约只适合粗略测单轨循环的情况。如果非要走这条路，倒还不如直接在 DAW 里面对素材做这些工作来得简单。 方法二：快进播放法这个是 Wwise 201 认证教程 中推荐的方法，海内外的一些设计师都有这样用的，见下图： 将父级容器的播放速度调大，那么播放时过渡涉及的 Music Segment 就能快进到过渡点附近。这时候如果想精听，则可以降回原速，除非你告诉我专业人士的耳朵都是 4 倍速的！ 这个方法的优点是： 概念简单。 对设计的污染少。只动一个播放速度参数，用后还是很容易调回来的，因为默认值一般都是 1。 但是缺点仍然很明显： 在 Music Playlist Editor 中，依然无法直接收听任意一对 Music Segment 的过渡，只能从头顺序播放。 这是一种渐进操作，无法一步定位到过渡点附近。 操作上对反射神经有一定要求 … 方法三：Seek 法这个技巧是海外设计师 Aaron Brown 分享的。基本原理是立足于 Event 及其 Seek（即寻址跳转）这个 Action。跟前两种方法相比，它更能满足本文开始分析的三条需求，但实际操作要绕点路。 Aaron Brown 的原始分享可以在 Wwise 的非官方 Facebook 群Wwise Wizards &amp; Witches中找到，但是他只给了粗略的示意图，如下图所示： 但我实操后发现在 Wwise 2017.1 中上面的方法并不能凑效，要修改一些做法。下面详细讲解一下。 原理这个方法是希望避免肉眼定位和等待，实现一键定位到音乐的过渡点附近，按照原速收听过渡。 Wwise 的 Event 中有 Seek 这个 Action 可以定位到播放文件中的指定位置。前两种方法其实也做了这个定位，只不过是用肉眼和手工操作来确保的：开始试听过渡的播放点必须要在同步点之前。而针对这点，Seek Action 只需设好跳转位置的数值就可以。并且，它还有服务于互动音乐的一条诱人的特性： Seek Action 的 Seek Percent（按百分比跳转）模式下，跳转是相对于 Entry Cue 和 Exit Cue 进行的。 打个比方，不管这些 Cue 设定在 Music Segment 的什么位置，即使我们把跳转设在 99% 处（即 Seek Percent 为 99%），它也绝对不会超出 Exit Cue 而误入 Post-Exit 段；对于单曲循环的情况，跳转百分比位置是相对循环区间来算的。有了这个条件，我们就可以放心定义跳转点来一键空降到过渡点附近了。 不过 Seek Action 还有一条重要的限制： Music Playlist Container 和 Motion 对象不支持 Seek。 而 Music Segment 不能控制过渡，只能依赖其父级容器，所以在 Event 中实现过渡的唯一希望就是 Music Switch Container 了。你大概明白了吧？我们要使用 State 切换来模拟所有的过渡情况，在切换状态之前执行 Seek 动作来直接跳转到过渡点之前的邻近位置，就能达到“直接”播放过渡段的目的。 State 切换要模拟的情况包括: 工程自身互动音乐设计中的状态过渡。 Music Playlist Container 里面的相邻 Music Segment 间过渡。 Music Segment 单曲循环的首尾衔接。 看起来好像很复杂，但其实只需要把要做过渡的 Music Segment 提取出来，分别关联一个 State，指派给一个测试用的 Music Switch Container 就可以了。 下面我们通过一个实例来说明做法。 做法示例我们还是以 Wwise 安装包自带的Sample Project为例来说明 Seek 法的具体操作。简单起见，我们就挑选下图中选中的两个 Music Segment 来举例： 这两个 Segment 也是Stealth这个 Music Playlist Container 中顺序播放的相邻对象（见本文第一张图），采用的过渡同步点为 Exit Cue。 首先，创建一个专用的 Music Switch Container，把Steath_Seg_01和Steath_Seg_02复制到它下面。见下图： 创建新的 Music Switch Container 是有原因的：在指定 Music Switch Container 的状态路径的时候，路径对应播放对象只能是该 Music Switch Container 的直接子对象，也就是说之前位于Stealth下面的对象如果不挪出来就无法直接关联到 State 上面去；而如果复制到原 Music Switch Container 下面，就又会污染设计。所以比较好的做法是直接创建一个新的 Music Switch Container。 这个专用容器的过渡规则一般只需要用默认的Any to Any规则就可以，但要注意默认会播放源段的 Post-Exit 和目标段的 Pre-Entry，不启用淡变。当然，你完全可以按需要来定制整条规则。这里我们重点强调 Exit Cue 的情况。 接着，创建一个新的 State Group，然后为两个 Music Segment 各创建一个 State。见下图： 下一步，回到测试专用的 Music Switch Container，设置好状态路径，让上面的 State 和 Music Segment 一一对应。见下图： 最后，我们创建测试事件。里面依序包含如下 Action： 我们让第一个 Set State Action（状态初始化）比 Play Action 稍早一点执行，确保在播放之前状态已经初始化成源状态，播放源 Segment。这里我们把 Play Action 的 Delay 设为0.01， Set State 的 Delay 为 0。 Seek Action 也比播放略提前，Seek 模式为Seek Percent，位置为90%。你可以视需要修改这个位置。注意：Aaron Brown 在 Wwise 2016.2 中采用 Seek All 这个 Action，Scope 设为 Global，但经测试发现在 Wwise 2017.1 中这个做法无效，要使用 Seek 才行。 后一个 Set State Action 也就是状态切换的动作比播放稍晚一点，确保不会覆盖第一个 Set State 操作，导致源 Segment 没能播放起来。所以这里的 Delay 设为0.02。 现在测试一下这个 Event，看是不是能一步到位试听过渡？ 如果要试听一个 Music Segment 单曲循环的首尾衔接，则可以把问题转化为“从这个段落过渡到它自己的副本”，唯一需要改变的就是要复制源 Music Segment，把它作为目标段落即可。 你可能会问：“我就用同一个 Music Segment，给它关联两个不同的 State 不行吗？”然而 Wwise 中，基于 State/Switch 过渡时前后必须为两个不同的对象，音乐引擎才会启动过渡行为。所以必须给原 Music Segment 做一个副本，才能通过切换 State 来测试自循环过渡。 为了简单，示例中我们就地在工程已有的 Work Unit 中创建试听用的临时对象和其它元素。这样做还是污染了现有设计的，因为 Work Unit 对应 XML 文件，是 Wwise 工程的设计内容实体。所以比较好的做法是创建测试专用的 Work Unit，这样就不会污染，且很容易一键删除所有测试元素。注意，测试对象只要保证不打到 SoundBank 里就不会影响游戏的实际性能。 进一步讨论为了试听一个小小的过渡，Seek 法看起来并不直观，需要好几步操作，这是它最明显的缺点。但是我们可以看到 Seek 法有独特的优势： 它可以满足我们的三条需求。 它不需要人工肉眼对位，也不依赖反应。这点别的工具很难做到。 设好的 Event、Music Switch Container 和 State 可以作为一套可复用的测试框架保留下来，用同一套框架甚至同一个事件测试各种过渡，只用反复改变事件 Action 列表中的 两个 State 就好。 整个流程可以通过 Wwise Authoring API（WAAPI）自动化脚本来加速。 除以上三种方法之外，还可以用 WAAPI 做后端来写一个简单的媒体播放器播放列表界面来达到传统的体验。 小结本文针对很多人提到的“听一下过渡好难”的痛点，总结了一下在不编程或自己写第三方 UI 的情况下，现有能加速试听过渡的方案，希望能给大家一点帮助，权当抛砖引玉，欢迎大家指正和探讨其它可能的技巧和方案。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[GDC17 音频见闻 - 空间音频 Spatial Audio（2）]]></title>
      <url>%2F2017%2F03%2F13%2FGDC17-Audio-Spatial-Audio-2%2F</url>
      <content type="text"><![CDATA[Wwise 2017.1 的空间音频新功能 上篇说到微软的 Project Triton 未来的方向恰好与 Wwise 2017.1 的一些新功能不谋而合，简单地说，Wwise]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[GDC17 音频见闻 - 空间音频 Spatial Audio（1）]]></title>
      <url>%2F2017%2F03%2F13%2FGDC17-%E9%9F%B3%E9%A2%91%E8%A7%81%E9%97%BB%EF%BC%881%EF%BC%89-%E7%A9%BA%E9%97%B4%E9%9F%B3%E9%A2%91-Spatial-Audio%2F</url>
      <content type="text"><![CDATA[《Gears of War 4》中的环境声学预处理技术继 Binaural 和 Ambisonics 之后，今年 GDC 上的空间音频热门关键字多了混响（Reverberation）、声障和声笼（Obstruction &amp; Occlusion）这些环境声学概念，标志着对沉浸音频体验发起的又一次冲锋。这些游戏音频界的旧瓶里最受瞩目的新酒之一当数微软研究院和《战争机器4》（GoW4）开发组的 Project Triton，即通过预先演算声波传播物理参数来辅助人工设计的环境声学效果方案。本次的演讲实际上是微软已启动六年之久系列研究的首次产品化成果。演讲幻灯片已放出。以下尝试稍加总结。 成果这乍一看很学术范的技术主要是为了解决游戏环境声学设计中的一大痛点：传统设计方法依赖在游戏地图中手工标注或绘制声学区域，再挂接音频效果器来实现室内混响和声障／声笼效果；音频中间件如 Wwise 的效果器控制参数一般是够用的，但在游戏中手工标注的工作量巨大且容易出错，实际开发工期紧，很难打磨调优。 不巧，玩家极易通过生活经验察觉这类设计错误，后果严重，参见《刺客信条：大革命》中曾出现的全局 bug。音频设计界早就希望能像物理渲染界一样自动化这个过程，为创意设计赢得时间。 演讲中放出的最终解决方案： 离线预处理：在游戏地图中自动选取采样位置，对各个位置上的发声体-听者结对（emitter-listener pair）根据几何数据自动做 3D 声波传播模拟并生成原始声学数据库； 解析：从原始声学数据自动提炼出一组感知参数值：直达波能量、反射波能量、反射波衰减率（wetness）和混响衰减率； 接入音频中间件：运行时通过查询数据库获取感知参数值，用来控制 Wwise 中的声障／声笼滤波器和辅助总线上的混响效果器，产生实时互动的声学效果。 用这种方法，设计师不再需要手动标注环境声学区域，可以专注于艺术效果设计，即通过感知参数来控制音频效果输出。结果不但错误少，且游戏中的实时性能也达到甚至优于项目初始要求。 一些细节： 声障值和声笼值分别用初始能量（直达声比例）和反射能量来代表； 区分室外和室内情况，方法是通过在室外设置理想边界，并测量从玩家位置发声后能抵达这条边界的能量占总能量的比例来推算室内-室外比，以此来做到平滑过渡； 原始声学数据计算用 100 台机器需要约 4 小时计算时间，初始数据为 50 TB，做解析后降为 100 MB。 经历很多学术报告大概也就到此为止了，让一部分听众感觉高山仰止，另一部分不知所云。然而这次两位主讲人–微软研究院的 Nikunj Raghuvanshi 和 Coalition 工作室的 John Tennant –继续披露了研发和产品化的详细经过，以机器人领域的恐怖谷现象为纲，讲述了从真实到艺术真实的探索（微信游戏音频群里尾巴老师语），体现了对基础研究和产品化过程深刻的理解，是演讲中我个人最喜欢的部分。 从 2011 年的 V1.0 到 2014 年的 V2.0 直到最终版，项目经历了标准的恐怖谷历程： V1.0 中初尝预处理甜头后，发现一些问题亟待解决，比如区分室内外和消除混响效果中的浑浊； 于是寄希望于自动化和仿真路线，火力全开，将模型复杂化：从 FDN 混响换成卷积混响，声学数据因此变成冲激响应，在增加室外效果器组分支的同时还增加了对早期反射和后期混响的区分，导致要控制 12 个混响单元； 不幸跌入恐怖谷，为了自救而后退一步，着重解决艺术真实问题，最后简化了模型，按时保质完成了产品化。 一些真实和艺术真实的折衷处理： 冲激响应路线很难控制质量：录音和测量人员不同，因此高度依赖配准，为后期调试带来困难，终弃； 混响效果受输入声音动态范围影响，将输入的真实动态范围做了艺术限制之后，清晰度得到提升； 与传统影视建立的艺术效果标准相比，物理计算中得出的直达声能量以及衰减时间，结合游戏具体玩法后，会出现不合心理期望的情况，终弃。 有意思的是，上面的道理很多其实是马后炮：是在主动作出简化混响模型的决定后从实践中领悟到的，又一次说明奥卡姆剃刀原则的普适性。 未来Triton 项目的未来计划包括在预处理模型中加入： 直达分量方向性、早期反射、户外回声； 动态几何结构，比如活动的门窗和物理毁坏。 巧的是，Triton 和 Wwise 不谋而合，这几条正是 GDC17 上 Wwise 2017.1 版本展出的新 Spatial Audio 功能的一部分，请看下篇。 相关资料 演讲幻灯片: ‘Gears of War 4’, Project Triton: Pre-Computed Environmental Wave Acoustics Engadget 文章：Microsoft Research helped ‘Gears of War 4’ sound so good Triton V1.0 论文：Raghuvanshi, et. al., SIGGRAPH 2010, “Precomputed wave simulation for real-time sound propagation of dynamic sources in complex scenes” Triton V2.0 论文：Raghuvanshi &amp; Snyder, SIGGRAPH 2014, “Parametric wave field coding for precomputed sound propagation”]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[补记 MIGS 2016 上的演讲见闻]]></title>
      <url>%2F2017%2F01%2F15%2Fmigs-2016%2F</url>
      <content type="text"><![CDATA[最近一次的蒙特利尔国际游戏峰会 MIGS 2016过去一阵子了，只有3岁的 MIGS 在规模上无法跟 GDC 这样的老字号相提并论，不过每年还是有些有用的技术演讲，在此追记一下自己去过那几场的要点，主要是音频专场。 Leonard Paul “用 Pure Data 为游戏实现 Procedural Audio” 音频设计师和教师 Leonard Paul 以 Unity 示例游戏作为蓝本介绍了用 Pure Data（PD）实现 procedural audio（下称 PA）音频设计一些可能性。会后他还发布了这次演讲的幻灯和录音。 在这个例子中 Leonard 展示了几个 PD patch。通过自己设计实现从 PD 到 Unity 的一整套 OSC（Open Sound Control）消息服务机制，建立了一条简单的音频原型迭代的管线：在 PD 中创建和修改设计，在 Unity 中测试，两端通过 OSC 沟通来试听和调整混音等。演示的声音大多采用简单的加法／减法／模态（Modal）实时合成方法，坦克碰撞声采用了 Karplus-Strong 算法。 关于 PD 生态的现状，Leonard 说 libpd 的性能还达不到游戏要求的实时性，但 Enzien Audio 的 Heavy 系统的性能很有希望。目前 Heavy 支持大部分 PD 的对象，只有极少数关键对象比如 expr～ 不支持。 Leonard 也表示在游戏项目中选用 PD 这样的系统有一些注意事项： 不应该为 PA 而 PA。从审美上不是所有的游戏都适合 PA，演讲采用的坦克游戏碰巧是美式动漫风，所以适合用常用的合成技术表现； 用 PD “做出声音”只是音频设计流程中的一方面，走这条路还需要自己实现通信协议、混音器、voice 控制，性能优化这些一般中间件里有的东西； 同一个功能可能有不同品质和性能代价的算法实现，可以考虑根据实时性能的波动切换算法以达到最优性价比； 在条件允许下，比如大公司和大型项目中一般还是以中间件为出发点。 感想：利用创意编程工具实现 PA 目前还是一个技术性很强的领域，Leonard 自我介绍时强调自己的编程背景并已经有 20 多年使用 Max（90 年代初还没有 MSP）和 PD 的经验也侧面佐证了这一点。 RJ Mattingly “手工打造游戏音频利器” RJ Mattingly 是 PopCap 的技术声音设计师。PopCap 现在全面采用 Unity + Wwise 的音频开发流程，在演讲中他介绍了为优化 PopCap 内部工作流程写的一些小脚本工具，基本都用 Python 语言实现。 SoundBank 管线工具PopCap 的 SoundBank 处理管线见上图。 他们早期基于 Perforce 的流程中声音设计师不但提交 Wwise 工程文件，还提交 SoundBank。这样一来因为 SoundBank 是团队共享的，所以容易出现冲突。RJ 的第一个显而易见的改进便是规定设计师不提交 SoundBank（设计产物），而只提交工程文件（设计本身），并在 Jenkins 管线中通过脚本使用 Wwise 自带的命令行工具 WwiseCli 生成项目的唯一一份 SoundBank，解决了冲突问题。 一个常见的人为错误是在生成 SoundBank 时漏加了文件或者多个 SoundBank 中有重复的音频源文件，这些错误有时几个礼拜之后才会发现。于是 RJ 利用 Wwise 中 SoundBank 生成的后处理 post-generation step 写了一个脚本来分析 Wwise 自动生成的日志，找到与缺少和重复文件相关的信息，并自动群发邮件。这样一来，错误一般都能当天发现并修正。 Event 工具在性能优化上，Wwise 中虽然有最大复音数限制机制，但有些时候项目会想从 Event 层面来做限制，比如三消游戏《Bejeweled》系列中的爆炸道具如不加限制会引爆上百个事件，目前 Wwise 中没有提供由设计师来指定事件数限制的流程。因为 Wwise 事件下有 Notes 这个属性，因为属性保存在事件所在的 WorkUnit（.wwu）文件中，RJ 于是把 Notes 当作特殊字段来用，写了一个脚本工具在 Notes 中加入自定义的事件限制文本编码，设计师可以在 Wwise 中进一步手动调整，然后工具会分析 .wwu 并生成游戏程序可以读取的 metadata 作为事件限制的参考数据。 动画配声工具在《Plants vs. Zombies: Heroes》中有 300 多个角色，每个角色有 5-20 个动画序列，所以手工配声工作量巨大。于是 RJ 写了一个 Unity UI 拓展能够改进这个流程，并能够自动比较 Unity 端登记的动画 Event 和 Wwise 设计工具端的 Event，保证在 Unity 端登记的 Wwise Event 确实存在。 设计师往往喜欢把 Unity 的动画导出成视频文件然后到 DAW 中配声，但 Unity 没有这种导出支持。于是 RJ 写了工具自动导出动画成视频，方法是：将动画帧自动截屏成图片，再用 ffmpeg 的命令行工具将这些图片批量组装成视频文件。 Benoit Alary “用于虚拟声学空间的沉浸式混响”Audiokinetic 的 Benoit Alary 做了关于 Audiokinetic 研发的新互动混响插件（代号 SynthSpace）的演讲，作为早先这篇博客的展开并演示了原型效果。 传统混响技术有其局限性。参数混响比如 FDN 算法族 难以加入逼真的互动效果，比如玩家在室内走动时，很难根据玩家离墙的远近自动调整早期反射效果。而在其它方面相对参数混响有优势的卷积混响如果想要克服这一点，则需要录制多个冲激响应（IR）来捕捉整个空间。暴雪在《Overwatch》中为了改进这点研发了自己的内部 Wwise 插件 Quad Delay 用来加入与环境互动的反射效果，见他们的 GDC 2016 演讲。 以往在解决这个问题上有两派： 几何方法：将混响问题中的声音传播退化为类几何光学问题，研究从声源出发的理想射线在封闭空间中的几何反射。但这种简化做法不考虑声波的干涉等性质，如果用于整个混响过程，则效果有局限。 波方法：直接模拟声波传播，考虑所有波的性质包括干涉。这种做法运算量巨大，目前唯一实际的做法是离线计算好各种参数并储存为数据库供应用程序实时检索使用，但对设计流程来说离线计算的开销可能就是小时甚至天的数量级。另一个问题是，波方法需要每秒 4 万次以上的反射取样，因此在数字音频采样率的限制下对高频的表现不会很好。 在游戏等媒体应用中，实际需求往往并不是完全逼真地模拟现实中的混响，而是需要给音频设计师足够的控制来达到某种艺术效果。 目前的趋势是混成混响（Hybrid Reverb）技术：拆分混响过程，利用几何方法来控制早期反射（early reflection），而用传统混响来控制后期混响（late reverb）。 SynthSpace 的这款 Wwise 混音器插件就是给高品质混响用户群特别是 VR／AR 项目准备的实用工具。 它的用法是在一条混响总线上加入此插件，实时接收游戏发送的空间鞋盒（shoebox）模型以及发声体和听者在空间中的位置，基于这些数据进行实时反射计算，取代参数混响中的 Pre-Delay 参数，设计师可以在 Wwise 中对反射等效果和性能需求做精确的设计，再结合其它混响效果实现完整的互动混响。《Overwatch》的 Quad Delay 插件是基于 4 个平面方向的环绕声方案，相比之下，SynthSpace 支持 6 个方向的三维空间，因而也支持 spatial audio，在传统游戏和 VR/AR 中都有用武之地。 演示用到了 Wwise 后续将发布的全新 3D 测试游戏地图，将作为 Cube Demo 基础上更适合测试声学效果的 demo 安装包。SynthSpace 将于 2017 年内面世，到时候可能会有正式的新名字。 Olivier Deriviere “环境音乐，互动配乐的下一步?”Olivier Deriviere 之前在 《Remember Me》（2013） 中将战斗音乐的互动性推到了新高度，这次他介绍了在万代南梦宫新作《Get Even》中的新实验：利用 Wwise 和 3D Audio 将环境声和音乐融为一体。之前在《DOOM》（2016）中已嗅到这种味道。这场据说是这届 MIGS 上最值得去的音频演讲，可惜没有去成，不过游戏在 GDC 2017 上会有首秀，很期待。 Wolff Dobson “机器学习、游戏和你”这是去的唯一一场非音频演讲。来自 Google 机器学习组的 Wolff Dobson这场大半是科普机器学习特别是深度学习及其新进展，也指出了游戏中机器学习的一些应用的可能性和已经用到的场合： 分析玩家的入坑、内购、弃坑规律，在预测到可能行为时推送合适的内容促进留存率； 分析游戏中玩家聊天记录判断情绪； 分析监测作弊行为； 分析玩家的玩法特征，让游戏内容作出适配； 分析电影中的真人动作和物理系统来自动生成游戏物理系统和动画； 分析玩家的操作和策略，利用强化学习给玩家策略建议； 分析生物面部特征，做出更自动化的捏脸系统； 自动生成内容：关卡、对白、NPC。 他也强调“玩家的乐趣”是终极目标，而不是为了机器学习而学习。比如，在角色扮演和第一人称游戏里面玩家的视野和注意力受限，所以镜头外的 AI 其实必要性不大，因为玩家要么注意不到，要么可能把 NPC 在 GPS 上的“出色”表现理解为是机器作弊。 他也提到了一些游戏以外的机器学习应用： 图片低清转高清 实时混合油画滤镜 自动生成卧室照片、唱片封套（之前我在朋友圈转过） 自动垃圾分类]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[第一天]]></title>
      <url>%2F2016%2F12%2F25%2FHello-Hexo-%E4%BD%A0%E5%A5%BD-Hexo%2F</url>
      <content type="text"><![CDATA[之前玩公众号，但发现在引用外链和离线写作方面有限制。很多时候我期待的是自由外链引用、离线为主、一键发布、迭代迁移方便的博客流程。 GitHub 的静态站点系统 GitHub Pages 支持按照软件开发流程来管理博客，通过纯文本标记格式比如 Markdown 写作存为本地文件，再一键发布到远程。 所以来 GitHub 试试。]]></content>
    </entry>

    
  
  
</search>
