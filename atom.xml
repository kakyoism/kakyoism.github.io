<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>kkBeep</title>
  <subtitle>互动音频用户</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://kakyoism.github.io/"/>
  <updated>2018-01-05T18:15:41.000Z</updated>
  <id>http://kakyoism.github.io/</id>
  
  <author>
    <name>北南</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>十条你可能不知道的 Wwise Launcher 用法</title>
    <link href="http://kakyoism.github.io/2018/01/04/%E4%BD%A0%E6%89%80%E4%B8%8D%E7%9F%A5%E9%81%93%E7%9A%84-Wwise-Launcher/"/>
    <id>http://kakyoism.github.io/2018/01/04/你所不知道的-Wwise-Launcher/</id>
    <published>2018-01-04T12:05:02.000Z</published>
    <updated>2018-01-05T18:15:41.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文基于以下软件版本：</p>
<ul>
<li>Wwise Launcher: 2017.11.30.720</li>
<li>Wwise: 2017.1.4.6407</li>
<li>macOS Sierra 10.12.6 (16G1114)</li>
</ul>
<p>从 2016 年起，在 Audiokinetic 官网点击下载 Wwise 的时候，你实际上下载的是 Wwise Launcher（下文简称 Launcher），到现在你应该已经习惯用 Launcher 来下载更新 Wwise 本身甚至管理本机上的多个工程和 Wwise 版本了，但 Launcher 可能还有一些不太明显的功能和注意事项对你会很有用，我们今天就来梳理一下吧！</p>
<h2 id="1-程序员：哪里有-Wwise-集成／整合方面的例程？"><a href="#1-程序员：哪里有-Wwise-集成／整合方面的例程？" class="headerlink" title="1. 程序员：哪里有 Wwise 集成／整合方面的例程？"></a>1. 程序员：哪里有 Wwise 集成／整合方面的例程？</h2><hr>
<p>我们可以通过 Launcher 来安装 Wwise 的<a href="https://www.audiokinetic.com/library/edge/?source=SDK&amp;id=soundengine__integration__samplecode.html" target="_blank" rel="external"><code>IntegrationDemo</code></a>。如果我们已经安装了 Wwise，但是没有找到这个 Demo，则需要打开 Launcher，找到<code>WWISE</code>页上我们的目标版本，然后修改安装。</p>
<img src="/2018/01/04/你所不知道的-Wwise-Launcher/modify-installs.jpg">
<p>勾选左边选项框中的<code>SDK (C++)</code>，和右边的目标平台。</p>
<img src="/2018/01/04/你所不知道的-Wwise-Launcher/install-sdk-demos.jpg">
<p>之后点击<code>Install...</code>开始安装。安装结束后切换到<code>SAMPLES</code>页，选中正确的 Wwise 版本（图中为<code>2017.1.4</code>），便可以看到<code>IntegrationDemo</code>了。</p>
<img src="/2018/01/04/你所不知道的-Wwise-Launcher/samples-demos.jpg">
<p>如果想运行 Demo，则直接点击<code>Run IntegrationDemo</code>；如果想打开对应的 Wwise 工程检查或修改声音设计内容，那么点击<code>Open in Wwise</code>。</p>
<p>如果想打开源码工程，则点击左边按钮的下拉菜单，之后打开 Demo 所在文件夹，</p>
<img src="/2018/01/04/你所不知道的-Wwise-Launcher/open-demo-code-projects.jpg">
<p>通过文件系统打开对应平台的子文件夹，找到并打开 IDE 工程文件。</p>
<img src="/2018/01/04/你所不知道的-Wwise-Launcher/open-demo-code-project-2s.jpg">
<p>在研究 IntegrationDemo 的时候，推荐对照<a href="https://www.audiokinetic.com/library/edge/?source=SDK&amp;id=index.html" target="_blank" rel="external"><code>Wwise SDK Help</code></a>文档来学习，特别是<code>声音引擎集成纵览</code>一节。</p>
<p>因为<code>IntegrationDemo</code>是 Wwise SDK 的一部分，Audiokinetic 会持续维护测试这组例程和对应的 Wwise 工程；每当有重要的新功能时，该 Demo 中一般会加入新功能演示，所以不论我们的项目用的是自研引擎还是商业引擎比如 Unity／Cocos2d-x，<code>IntegrationDemo</code>都是我们学习 Wwise 整合代码最好的帮手。</p>
<p>更重要的是，假如我们的项目出现了奇怪的问题，开始怀疑是不是 Wwise 的 bug 时，可以首先尝试用 IntegrationDemo 来对照重现问题，Demo 提供的是高度简化和反复测试过的环境，有助于隔离发现应用端的整合问题。Demo 中重现不了的问题最终往往会证明来自应用端的使用不当。</p>
<h2 id="2-我们公司大部分机器在内网，怎么安装-Wwise？"><a href="#2-我们公司大部分机器在内网，怎么安装-Wwise？" class="headerlink" title="2. 我们公司大部分机器在内网，怎么安装 Wwise？"></a>2. 我们公司大部分机器在内网，怎么安装 Wwise？</h2><hr>
<p>我们可以用某台外网机安装需要的 Wwise 组件，然后通过 Launcher 制作离线安装包给内网机使用：</p>
<img src="/2018/01/04/你所不知道的-Wwise-Launcher/offline-installers.jpg">
<p>做好的离线包除了组件文件夹<code>bundle</code>外，会自带一个配套的 Launcher 安装包：</p>
<img src="/2018/01/04/你所不知道的-Wwise-Launcher/offline-installer-2s.jpg">
<p>最后将离线安装包发送到各台内网机上，在内网机上分别装好包里自带的 Launcher，再打开 Launcher 定位到离线包来安装。</p>
<img src="/2018/01/04/你所不知道的-Wwise-Launcher/offline-installer-3s.jpg">
<h2 id="3-我下载安装了-Wwise，但是我的工程在生成-SoundBank-时报错，说最多只能使用-200-个声音文件，怎么办？"><a href="#3-我下载安装了-Wwise，但是我的工程在生成-SoundBank-时报错，说最多只能使用-200-个声音文件，怎么办？" class="headerlink" title="3. 我下载安装了 Wwise，但是我的工程在生成 SoundBank 时报错，说最多只能使用 200 个声音文件，怎么办？"></a>3. 我下载安装了 Wwise，但是我的工程在生成 SoundBank 时报错，说最多只能使用 200 个声音文件，怎么办？</h2><hr>
<p>这说明我们的工程没有添加合适的 Wwise 授权码。我们需要打开 Launcher，<strong>登录我们的 Audiokinetic 账号</strong>，在<code>PROJECTS</code>页找到我们的 Wwise 工程，点击钥匙状按钮，这时我们有两个选择：1）注册新项目，并等待 Audiokinetic 商务联系人批准项目注册并接收系统邮件取得授权码。</p>
<img src="/2018/01/04/你所不知道的-Wwise-Launcher/project-licenses.jpg">
<p>这时我们会来到官网项目注册页面，需要根据向导填好所有信息并提交申请。之后如果确信申请通过了但没有收到系统邮件，则最好检查一下垃圾邮箱。</p>
<img src="/2018/01/04/你所不知道的-Wwise-Launcher/project-license-2s.jpg">
<p>2）如果我们的项目确定已经注册了，只是没有导入授权码，则需要注意：每个 Wwise 项目在 Audiokinetic 官网上都有若干管理员（Wwise Project Leader)，他们一般是我们自己项目团队的成员。可以联系管理员把我们的 Audiokinetic 账号加入该项目，之后便可以在 Launcher 里工程的<code>Set Project License</code>菜单中找到对应的项目授权码并授权项目了，<strong>做授权码导入操作时要确保关闭已经打开的工程</strong>。</p>
<img src="/2018/01/04/你所不知道的-Wwise-Launcher/project-licenses-2.jpg">
<h2 id="4-如何安装-Unity-集成？"><a href="#4-如何安装-Unity-集成？" class="headerlink" title="4. 如何安装 Unity 集成？"></a>4. 如何安装 Unity 集成？</h2><hr>
<p>假设我们的电脑上已经装了 Unity，并且创建了 Unity 工程，而我们现在想给其中某个 Unity 工程安装 Wwise 集成。这时我们需要来到 Launcher 的<code>UNITY</code>页，点开顶部菜单的浏览按钮：</p>
<img src="/2018/01/04/你所不知道的-Wwise-Launcher/unity-browse-projects.jpg">
<p>选中目标 Unity 工程并确认后，在<code>UNITY</code>页的工程列表里就能看到这个工程了。接下来我们有两个选择：1）直接从官网下载 Unity 集成并同时安装，</p>
<img src="/2018/01/04/你所不知道的-Wwise-Launcher/unity-integrates.jpg">
<p>或者 2）先下载离线安装包，</p>
<img src="/2018/01/04/你所不知道的-Wwise-Launcher/unity-offline-1s.jpg">
<p>然后通过 Launcher 手动安装。</p>
<img src="/2018/01/04/你所不知道的-Wwise-Launcher/unity-offline-2s.jpg">
<p>注意，无论用哪种方法，安装期间必须<strong>关闭所有打开的 Unity 编辑器</strong>。</p>
<h2 id="5-通过-Launcher-安装和升级-Unity-集成的时候失败了，怎么办？"><a href="#5-通过-Launcher-安装和升级-Unity-集成的时候失败了，怎么办？" class="headerlink" title="5. 通过 Launcher 安装和升级 Unity 集成的时候失败了，怎么办？"></a>5. 通过 Launcher 安装和升级 Unity 集成的时候失败了，怎么办？</h2><hr>
<p>首先我们需要根据<a href="https://www.audiokinetic.com/library/edge/?source=Unity&amp;id=pg__releasenotes.html" target="_blank" rel="external">Unity 集成版本说明</a>来确认要安装的 Wwise 版本对应支持的 Unity 版本。</p>
<p>如果版本都是对的，则需要打开 Unity 编辑器观察控制台里的错误信息。Wwise Unity 集成安装时需要运行 Unity 程序来做一些初始化或者升级工作，这个过程中 Unity 工程内部可能出现的错误并不会在 Launcher 界面上显示出来。</p>
<h2 id="6-我需要根据特定-Wwise-SDK-库版本来重新编译-Wwise-Unity-集成，怎么办？"><a href="#6-我需要根据特定-Wwise-SDK-库版本来重新编译-Wwise-Unity-集成，怎么办？" class="headerlink" title="6. 我需要根据特定 Wwise SDK 库版本来重新编译 Wwise Unity 集成，怎么办？"></a>6. 我需要根据特定 Wwise SDK 库版本来重新编译 Wwise Unity 集成，怎么办？</h2><hr>
<p>有时候我们等不及官方 Unity 集成补丁，而想基于某个已经下载好的原生 SDK 补丁库来重新构建 Unity 集成， 这时我们需要的是 Unity 集成的源码包，可以在 Launcher 的<code>UNITY</code>页下载离线安装包来取得（见<code>如何安装 Unity 集成？</code>）。</p>
<p>离线包的格式为 .tar.xz，一般我们需要通过 Launcher 安装集成来解出源码包来。如果想手动解包，则需要安装可以解压<code>XZ</code>和<code>TAR</code>格式的程序。比如在 macOS 上，我们可以通过<a href="https://brew.sh" target="_blank" rel="external">Homebrew</a>来安装<code>xz</code>这个包，之后即可通过命令行<code>xz -d</code> 来解包了。源码包的文件一般以<code>_Src.zip</code>结尾。</p>
<p>重新编译 Unity 集成的方法见<a href="https://www.audiokinetic.com/library/edge/?source=Unity&amp;id=pg__building.html" target="_blank" rel="external">官方文档</a>。</p>
<h2 id="7-新手怎么学习-Wwise-Unity-集成？"><a href="#7-新手怎么学习-Wwise-Unity-集成？" class="headerlink" title="7. 新手怎么学习 Wwise Unity 集成？"></a>7. 新手怎么学习 Wwise Unity 集成？</h2><hr>
<p>可以通过 Launcher 安装运行 Unity 集成示例，再对照<a href="https://www.audiokinetic.com/library/edge/?source=Unity&amp;id=main.html" target="_blank" rel="external">官方文档</a>学习。</p>
<img src="/2018/01/04/你所不知道的-Wwise-Launcher/unity-demos.jpg">
<h2 id="8-新手怎么学习-Wwise-Unreal-Engine-集成？"><a href="#8-新手怎么学习-Wwise-Unreal-Engine-集成？" class="headerlink" title="8. 新手怎么学习 Wwise Unreal Engine 集成？"></a>8. 新手怎么学习 Wwise Unreal Engine 集成？</h2><hr>
<p>我们有两个选择：1）可以通过 Launcher 的<code>UNREAL ENGINE</code>页安装运行 Unreal 集成示例，再对照<a href="https://www.audiokinetic.com/library/edge/?source=UE4&amp;id=index.html" target="_blank" rel="external">官方文档</a>学习。</p>
<img src="/2018/01/04/你所不知道的-Wwise-Launcher/unreal-demos.jpg">
<p>2）也可以通过 Launcher 安装运行 Wwise 的空间音频 Demo：Wwise Audio Lab</p>
<img src="/2018/01/04/你所不知道的-Wwise-Launcher/wal-1s.jpg">
<img src="/2018/01/04/你所不知道的-Wwise-Launcher/wal-2s.jpg">
<h2 id="9-Launcher-操作中出现错误或者操作失败怎么办？"><a href="#9-Launcher-操作中出现错误或者操作失败怎么办？" class="headerlink" title="9. Launcher 操作中出现错误或者操作失败怎么办？"></a>9. Launcher 操作中出现错误或者操作失败怎么办？</h2><hr>
<p>我们可以去<code>?</code>页的<code>About</code>，</p>
<img src="/2018/01/04/你所不知道的-Wwise-Launcher/log-1s.jpg">
<p>找到 Launcher 的完整日志，</p>
<img src="/2018/01/04/你所不知道的-Wwise-Launcher/log-2s.jpg">
<p>然后想办法汇报给 Audiokinetic 的项目技术支持或<a href="https://www.audiokinetic.com/qa/" target="_blank" rel="external">社区问答论坛</a>。</p>
<p>最常见的问题是网络问题，出这类问题的时候如果开了 VPN，则可以尝试关闭了 VPN 再使用 Launcher。</p>
<h2 id="10-怎样了解-Audiokinetic-的新闻和最新技术？"><a href="#10-怎样了解-Audiokinetic-的新闻和最新技术？" class="headerlink" title="10. 怎样了解 Audiokinetic 的新闻和最新技术？"></a>10. 怎样了解 Audiokinetic 的新闻和最新技术？</h2><hr>
<p>我们可以打开 Launcher 的首页，便可以看到 Audiokinetic 的英文版新闻和最新博客。</p>
<img src="/2018/01/04/你所不知道的-Wwise-Launcher/home-feedss.jpg">
<p>首页上还有社区问答论坛的最新提问，可以从中学习其他用户的经验。</p>
<p>如果要看中文版，目前可以先点击 Launcher 首页任何链接来到 Audiokinetic 官网，然后切换语言为简体中文。</p>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><hr>
<p>越来越多的集成开发环境包括 Unity 和 Unreal Engine 利用独立于编辑器的 Launcher（启动器）作为控制中心程序来管理工程和资源。这样做，一来可以方便用户管理多个引擎版本和工程，避免和操作系统文件管理器中铺天盖地的文件夹和文件类型缠斗，甚至发生零散文件操作引起的意外；二来可以整合引擎开发商提供的一系列服务。在 Wwise 工作流程中，Wwise Launcher 正在扮演类似的角色。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文基于以下软件版本：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Wwise Launcher: 2017.11.30.720&lt;/li&gt;
&lt;li&gt;Wwise: 2017.1.4.6407&lt;/li&gt;
&lt;li&gt;macOS Sierra 10.12.6 (16G1114)&lt;/li&gt;
&lt;/ul&gt;

    
    </summary>
    
    
      <category term="wwise" scheme="http://kakyoism.github.io/tags/wwise/"/>
    
  </entry>
  
  <entry>
    <title>快速试听 Wwise 互动音乐的过渡</title>
    <link href="http://kakyoism.github.io/2017/10/29/quick-auditioning-music-transitions/"/>
    <id>http://kakyoism.github.io/2017/10/29/quick-auditioning-music-transitions/</id>
    <published>2017-10-29T10:23:07.000Z</published>
    <updated>2017-11-01T00:47:25.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文探讨的所有问题和解决方案都<strong>基于 Wwise 2017.1.x</strong>。不对后续版本负责。</p>
<h2 id="起因：听一下过渡好难"><a href="#起因：听一下过渡好难" class="headerlink" title="起因：听一下过渡好难"></a>起因：听一下过渡好难</h2><p>利用 Wwise 的互动音乐功能可以用小段音乐编组搭建出动态和互动的曲式和织体，但搭完了之后你还是得用耳朵试听乐段间的过渡，确保衔接在音乐意义上是无缝的。截至 Wwise 2017.1，不少人在这里遇到了麻烦，见下图：</p>
<!--![](quick-auditioning-music-transitions/mpe.png)-->
<img src="/2017/10/29/quick-auditioning-music-transitions/mpe.png">
<p>这个例子来自 Wwise 自带的示例工程<code>Sample Project</code>（可以从Wwise Launcher 的<code>SAMPLES</code>页下打开），在 Music Playlist Editor 中，<code>Stealth</code>这个 Music Playlist Container 中有一个 Sequence Continuous 模式的 Music Segment 编组，图中正在试听前两个 Music Segment 间的过渡。这时，由于<code>Stealth</code>采用的过渡规则中，Source 段用了<code>Exit source at Exit Cue</code>这条同步规则，见下图：</p>
<!--![](quick-auditioning-music-transitions/transition-exit-cue.png)-->
<img src="/2017/10/29/quick-auditioning-music-transitions/transition-exit-cue.png">
<p>Exit Cue 一般靠近曲子尾声，所以你必须把<code>Stealth_Seg_01</code>从头听到 Exit Cue 处才能开始试听和<code>Stealth_Seg_02</code>间的过渡，如果曲子很长，这样就很浪费时间；还有更惨的：当要听的过渡在一个很长的连续列表的中间靠后时，即便同步点是 Next Bar 这样近距离的，每次你还都得从最顶上听起。如下图：</p>
<!--![](quick-auditioning-music-transitions/mpe-mid-seg.png)-->
<img src="/2017/10/29/quick-auditioning-music-transitions/mpe-mid-seg.png">
<p>要听<code>Seg 02b (B)</code>到下一段的过渡时，你每次都得从<code>Seg 01a (A)</code>听起。上图里还比较仁慈，每个段落都只循环了一次，万一有些会循环有限次，万一播着中间接了个电话，… 你懂的。</p>
<p>于是你又下意识地跑到 Music Segment Editor 界面中想对着波形迅速定位到过渡点附近听，结果发现一次又只能试听一个 Segment，见下图：</p>
<!--![](quick-auditioning-music-transitions/mse.png)-->
<img src="/2017/10/29/quick-auditioning-music-transitions/mse.png">
<p>所以还是快不起来。</p>
<p>在别的情况下，也会有类似问题：</p>
<ul>
<li>确认单个 Music Segment 的循环无缝时。</li>
<li>试听 Music Switch Container 下的状态切换时。</li>
</ul>
<p>需要强调的是，麻烦大小和设计有关，短小的 Music Segment 可能几乎感觉不到。</p>
<p>面对这些情况，<strong>你的需求大概是这么三条</strong>：</p>
<ol>
<li>能从播放列表中直接挑出任何一对 Music Segment 来听过渡，不管它们在什么地方。</li>
<li>能定位到过渡点附近开始听。</li>
<li>能试听单曲循环的首尾衔接。</li>
</ol>
<p>换句话说：如今主流媒体播放器能做到的一些事情。</p>
<!--![](quick-auditioning-music-transitions/media-player.png)-->
<img src="/2017/10/29/quick-auditioning-music-transitions/media-player.png">
<p>上图中，如果你想听<code>Say</code>和<code>Architect</code>这两首曲子间的过渡（假设有的话），那么只需要鼠标双击<code>Say</code>这首，然后用底部进度条定位到尾部收听即可。如果要测自循环，则只需要把循环模式调到单曲循环就行了（注：Wwise 中由于有同步点的问题，常规的进度条还不够）。</p>
<p>相比之下，我们发现：<strong>Wwise 虽然提供了搭建非线性音乐结构的一整套工具，但其 UI 的预览功能不支持线性媒体播放器中的列表定点播放体验。</strong> 当然，反过来大多数线性媒体播放器也不支持 Wwise 提供的众多非线性播放功能。</p>
<p>在 Wwise 在 UI 上做出改进之前，我们暂时还得面对这个问题。</p>
<p>好消息是，“解决方法“（Hack）还是有的，虽然都不完美！<br>我们来看看到 Wwise 2017.1 版本为止，目前已知的三种方法。我把它们按从直观到抽象排了序。</p>
<h2 id="方法一：手动拼接法"><a href="#方法一：手动拼接法" class="headerlink" title="方法一：手动拼接法"></a>方法一：手动拼接法</h2><p>看到标题你估计已经有点失望了。没错，这个方法很简单粗暴：通过复制粘贴把想要一起听过渡的几个 Clip 放到 Music Segment Editor 的多轨界面上，手动确保各个 Clip 的 Exit Cue 和 Entry Cue 彼此对齐，最后通过光标直接定位到过渡点附近收听播放。如果要测某一轨的无缝循环，那就把该轨上的内容复制一遍紧贴在自己的尾巴上。</p>
<p>实际操作中有个麻烦：在 Music Segment Editor 下对齐来自两个 Music Segment 的 Clip 时，只有一个 Segment 的 Exit Cue 和 Entry Cue 能显示出来，另一个的则看不到。所以你可能要另想办法来对齐同步点，比如用 Clip handle 临时裁剪掉看不到 cue 的 Music Segment 的 Pre-Entry 或者 Post-Exit 部分，不然很难肉眼对齐。</p>
<p>这个方法的优点是：</p>
<ol>
<li>概念简单，接近 DAW 里面的操作习惯。</li>
<li>能通过交互来精确定位到过渡点附近。</li>
<li>可以试听任何 Music Segment 甚至单个 Clip 的组合。</li>
</ol>
<p>但缺点很明显：</p>
<ol>
<li>用来拼接 Music Segment 的临时操作会改动 Music Segment，污染了设计本身。事后还得清理现场。虽然可以创建专门的“测试段落”，但就要维护这个多轨测试对象，并不轻松。</li>
<li>很难快速测试多轨 Music Segment 间的过渡。上面说的 Clip handle 操作对各轨可能都要做一遍。</li>
<li>手动操作繁琐，对齐容易出错。</li>
</ol>
<p>这个方法大约只适合粗略测单轨循环的情况。如果非要走这条路，倒还不如直接在 DAW 里面对素材做这些工作来得简单。</p>
<h2 id="方法二：快进播放法"><a href="#方法二：快进播放法" class="headerlink" title="方法二：快进播放法"></a>方法二：快进播放法</h2><p>这个是 <a href="https://www.audiokinetic.com/courses/wwise201/?source=wwise201&amp;id=configuring_multi_group_playlists_setting_randomized_loop_counts" target="_blank" rel="external">Wwise 201 认证教程</a> 中推荐的方法，海内外的一些设计师都有这样用的，见下图：</p>
<!--![](quick-auditioning-music-transitions/playbackspeed.png)-->
<img src="/2017/10/29/quick-auditioning-music-transitions/playbackspeed.png">
<p>将父级容器的播放速度调大，那么播放时过渡涉及的 Music Segment 就能快进到过渡点附近。这时候如果想精听，则可以降回原速，除非你告诉我专业人士的耳朵都是 4 倍速的！</p>
<p>这个方法的优点是：</p>
<ol>
<li>概念简单。</li>
<li>对设计的污染少。只动一个播放速度参数，用后还是很容易调回来的，因为默认值一般都是 1。</li>
</ol>
<p>但是缺点仍然很明显：</p>
<ol>
<li>在 Music Playlist Editor 中，依然无法直接收听任意一对 Music Segment 的过渡，只能从头顺序播放。</li>
<li>这是一种渐进操作，无法一步定位到过渡点附近。</li>
<li>操作上对反射神经有一定要求 …</li>
</ol>
<h2 id="方法三：Seek-法"><a href="#方法三：Seek-法" class="headerlink" title="方法三：Seek 法"></a>方法三：Seek 法</h2><p>这个技巧是海外设计师 Aaron Brown 分享的。基本原理是立足于 Event 及其 Seek（即寻址跳转）这个 Action。跟前两种方法相比，它更能满足本文开始分析的三条需求，但实际操作要绕点路。</p>
<p>Aaron Brown 的原始分享可以在 Wwise 的非官方 Facebook 群<code>Wwise Wizards &amp; Witches</code>中找到，但是他只给了粗略的示意图，如下图所示：</p>
<!--![](quick-auditioning-music-transitions/wwise-tips-audition-transitions.jpg)-->
<img src="/2017/10/29/quick-auditioning-music-transitions/wwise-tips-audition-transitions.jpg">
<p>但我实操后发现在 Wwise 2017.1 中上面的方法并不能凑效，要修改一些做法。下面详细讲解一下。</p>
<h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>这个方法是希望避免肉眼定位和等待，实现一键定位到音乐的过渡点附近，按照原速收听过渡。</p>
<p>Wwise 的 Event 中有 Seek 这个 Action 可以定位到播放文件中的指定位置。<strong>前两种方法其实也做了这个定位，只不过是用肉眼和手工操作来确保的：开始试听过渡的播放点必须要在同步点之前。</strong>而针对这点，Seek Action 只需设好跳转位置的数值就可以。并且，它还有服务于互动音乐的<a href="https://www2.audiokinetic.com/library/edge/?source=Help&amp;id=event_actions_list#bp1307910" target="_blank" rel="external">一条诱人的特性</a>：</p>
<ul>
<li>Seek Action 的 Seek Percent（按百分比跳转）模式下，跳转是相对于 Entry Cue 和 Exit Cue 进行的。</li>
</ul>
<p>打个比方，不管这些 Cue 设定在 Music Segment 的什么位置，即使我们把跳转设在 99% 处（即 Seek Percent 为 99%），它也绝对不会超出 Exit Cue 而误入 Post-Exit 段；对于单曲循环的情况，跳转百分比位置是相对循环区间来算的。有了这个条件，我们就可以放心定义跳转点来一键空降到过渡点附近了。</p>
<p>不过 Seek Action 还有<a href="https://www2.audiokinetic.com/library/edge/?source=Help&amp;id=event_actions_list#seek_seekall_notes_and_restrictions" target="_blank" rel="external">一条重要的限制</a>：</p>
<ul>
<li>Music Playlist Container 和 Motion 对象不支持 Seek。</li>
</ul>
<p>而 Music Segment 不能控制过渡，只能依赖其父级容器，所以在 Event 中实现过渡的唯一希望就是 Music Switch Container 了。你大概明白了吧？<strong>我们要使用 State 切换来模拟所有的过渡情况，在切换状态之前执行 Seek 动作来直接跳转到过渡点之前的邻近位置，就能达到“直接”播放过渡段的目的。</strong></p>
<p>State 切换要模拟的情况包括:</p>
<ol>
<li>工程自身互动音乐设计中的状态过渡。</li>
<li>Music Playlist Container 里面的相邻 Music Segment 间过渡。</li>
<li>Music Segment 单曲循环的首尾衔接。</li>
</ol>
<p>看起来好像很复杂，但其实只需要把要做过渡的 Music Segment 提取出来，分别关联一个 State，指派给一个测试用的 Music Switch Container 就可以了。</p>
<p>下面我们通过一个实例来说明做法。</p>
<h3 id="做法示例"><a href="#做法示例" class="headerlink" title="做法示例"></a>做法示例</h3><p>我们还是以 Wwise 安装包自带的<code>Sample Project</code>为例来说明 Seek 法的具体操作。简单起见，我们就挑选下图中选中的两个 Music Segment 来举例：</p>
<!--![](quick-auditioning-music-transitions/sample-segments.png)
-->
<img src="/2017/10/29/quick-auditioning-music-transitions/sample-segments.png">
<p>这两个 Segment 也是<code>Stealth</code>这个 Music Playlist Container 中顺序播放的相邻对象（见本文第一张图），采用的过渡同步点为 Exit Cue。</p>
<p><strong>首先，创建一个专用的 Music Switch Container，把<code>Steath_Seg_01</code>和<code>Steath_Seg_02</code>复制到它下面。</strong>见下图：</p>
<!--![](quick-auditioning-music-transitions/sample-dup-msc.png)-->
<img src="/2017/10/29/quick-auditioning-music-transitions/sample-dup-msc.png">
<p>创建新的 Music Switch Container 是有原因的：在指定 Music Switch Container 的状态路径的时候，路径对应播放对象只能是该 Music Switch Container 的直接子对象，也就是说之前位于<code>Stealth</code>下面的对象如果不挪出来就无法直接关联到 State 上面去；而如果复制到原 Music Switch Container 下面，就又会污染设计。所以比较好的做法是直接创建一个新的 Music Switch Container。</p>
<p>这个专用容器的过渡规则一般只需要用默认的<code>Any to Any</code>规则就可以，但要注意默认会播放源段的 Post-Exit 和目标段的 Pre-Entry，不启用淡变。当然，你完全可以按需要来定制整条规则。这里我们重点强调 Exit Cue 的情况。</p>
<p><strong>接着，创建一个新的 State Group，然后为两个 Music Segment 各创建一个 State。</strong>见下图：</p>
<!--![](quick-auditioning-music-transitions/sample-states.png)-->
<img src="/2017/10/29/quick-auditioning-music-transitions/sample-states.png">
<p><strong>下一步，回到测试专用的 Music Switch Container，设置好状态路径，让上面的 State 和 Music Segment 一一对应。</strong>见下图：</p>
<!--![](quick-auditioning-music-transitions/sample-paths.png)-->
<img src="/2017/10/29/quick-auditioning-music-transitions/sample-paths.png">
<p><strong>最后，我们创建测试事件</strong>。里面依序包含如下 Action：</p>
<!--![](quick-auditioning-music-transitions/sample-event.png)-->
<img src="/2017/10/29/quick-auditioning-music-transitions/sample-event.png">
<ul>
<li>我们让第一个 Set State Action（状态初始化）比 Play Action 稍早一点执行，确保在播放之前状态已经初始化成源状态，播放源 Segment。这里我们把 Play Action 的 Delay 设为<code>0.01</code>， Set State 的 Delay 为 <code>0</code>。</li>
<li>Seek Action 也比播放略提前，Seek 模式为<code>Seek Percent</code>，位置为<code>90%</code>。你可以视需要修改这个位置。注意：Aaron Brown 在 Wwise 2016.2 中采用 Seek All 这个 Action，Scope 设为 Global，但经测试发现在 Wwise 2017.1 中这个做法无效，要使用 Seek 才行。</li>
<li>后一个 Set State Action 也就是状态切换的动作比播放稍晚一点，确保不会覆盖第一个 Set State 操作，导致源 Segment 没能播放起来。所以这里的 Delay 设为<code>0.02</code>。</li>
</ul>
<p>现在测试一下这个 Event，看是不是能一步到位试听过渡？</p>
<p>如果要试听一个 Music Segment 单曲循环的首尾衔接，则可以把问题转化为“从这个段落过渡到它自己的副本”，唯一需要改变的就是要复制源 Music Segment，把它作为目标段落即可。</p>
<p>你可能会问：“我就用同一个 Music Segment，给它关联两个不同的 State 不行吗？”然而 Wwise 中，基于 State/Switch 过渡时前后必须为两个不同的对象，音乐引擎才会启动过渡行为。所以必须给原 Music Segment 做一个副本，才能通过切换 State 来测试自循环过渡。</p>
<p>为了简单，示例中我们就地在工程已有的 Work Unit 中创建试听用的临时对象和其它元素。这样做还是污染了现有设计的，因为 Work Unit 对应 XML 文件，是 Wwise 工程的设计内容实体。所以比较好的做法是创建测试专用的 Work Unit，这样就不会污染，且很容易一键删除所有测试元素。注意，测试对象只要保证不打到 SoundBank 里就不会影响游戏的实际性能。</p>
<h3 id="进一步讨论"><a href="#进一步讨论" class="headerlink" title="进一步讨论"></a>进一步讨论</h3><p>为了试听一个小小的过渡，Seek 法看起来并不直观，需要好几步操作，这是它最明显的缺点。但是我们可以看到 Seek 法有独特的优势：</p>
<ol>
<li>它可以满足我们的三条需求。</li>
<li>它不需要人工肉眼对位，也不依赖反应。这点别的工具很难做到。</li>
<li>设好的 Event、Music Switch Container 和 State 可以作为一套可复用的测试框架保留下来，用同一套框架甚至同一个事件测试各种过渡，只用反复改变事件 Action 列表中的 两个 State 就好。</li>
<li>整个流程可以通过 Wwise Authoring API（WAAPI）自动化脚本来加速。</li>
</ol>
<p>除以上三种方法之外，还可以用 WAAPI 做后端来写一个简单的媒体播放器播放列表界面来达到传统的体验。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文针对很多人提到的“听一下过渡好难”的痛点，总结了一下在不编程或自己写第三方 UI 的情况下，现有能加速试听过渡的方案，希望能给大家一点帮助，权当抛砖引玉，欢迎大家指正和探讨其它可能的技巧和方案。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文探讨的所有问题和解决方案都&lt;strong&gt;基于 Wwise 2017.1.x&lt;/strong&gt;。不对后续版本负责。&lt;/p&gt;
&lt;h2 id=&quot;起因：听一下过渡好难&quot;&gt;&lt;a href=&quot;#起因：听一下过渡好难&quot; class=&quot;headerlink&quot; title=&quot;起因：听一
    
    </summary>
    
      <category term="GameAudio" scheme="http://kakyoism.github.io/categories/GameAudio/"/>
    
    
      <category term="wwise, interactivemusic" scheme="http://kakyoism.github.io/tags/wwise-interactivemusic/"/>
    
  </entry>
  
  <entry>
    <title>GDC17 音频见闻 - 空间音频 Spatial Audio（2）</title>
    <link href="http://kakyoism.github.io/2017/03/13/GDC17-Audio-Spatial-Audio-2/"/>
    <id>http://kakyoism.github.io/2017/03/13/GDC17-Audio-Spatial-Audio-2/</id>
    <published>2017-03-13T09:55:57.000Z</published>
    <updated>2017-05-02T00:32:24.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Wwise-2017-1-的空间音频新功能"><a href="#Wwise-2017-1-的空间音频新功能" class="headerlink" title="Wwise 2017.1 的空间音频新功能"></a>Wwise 2017.1 的空间音频新功能</h2><img src="/2017/03/13/GDC17-Audio-Spatial-Audio-2/sa-wwise-wal.jpg" title="全新 Spatial Audio 测试地图：Wwise Audio Lab">
<p>上篇说到微软的 Project Triton 未来的方向恰好与 Wwise 2017.1 的一些新功能不谋而合，简单地说，Wwise</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Wwise-2017-1-的空间音频新功能&quot;&gt;&lt;a href=&quot;#Wwise-2017-1-的空间音频新功能&quot; class=&quot;headerlink&quot; title=&quot;Wwise 2017.1 的空间音频新功能&quot;&gt;&lt;/a&gt;Wwise 2017.1 的空间音频新功能&lt;/
    
    </summary>
    
      <category term="GameAudio" scheme="http://kakyoism.github.io/categories/GameAudio/"/>
    
    
      <category term="conference, gdc17, reverb, obstruction-occlusion, spatialaudio" scheme="http://kakyoism.github.io/tags/conference-gdc17-reverb-obstruction-occlusion-spatialaudio/"/>
    
  </entry>
  
  <entry>
    <title>GDC17 音频见闻 - 空间音频 Spatial Audio（1）</title>
    <link href="http://kakyoism.github.io/2017/03/13/GDC17-%E9%9F%B3%E9%A2%91%E8%A7%81%E9%97%BB%EF%BC%881%EF%BC%89-%E7%A9%BA%E9%97%B4%E9%9F%B3%E9%A2%91-Spatial-Audio/"/>
    <id>http://kakyoism.github.io/2017/03/13/GDC17-音频见闻（1）-空间音频-Spatial-Audio/</id>
    <published>2017-03-13T05:50:33.000Z</published>
    <updated>2017-05-02T00:32:24.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="《Gears-of-War-4》中的环境声学预处理技术"><a href="#《Gears-of-War-4》中的环境声学预处理技术" class="headerlink" title="《Gears of War 4》中的环境声学预处理技术"></a>《Gears of War 4》中的环境声学预处理技术</h2><p>继 Binaural 和 Ambisonics 之后，今年 GDC 上的空间音频热门关键字多了<em>混响</em>（Reverberation）、<em>声障和声笼</em>（Obstruction &amp; Occlusion）这些环境声学概念，标志着对沉浸音频体验发起的又一次冲锋。这些游戏音频界的旧瓶里最受瞩目的新酒之一当数微软研究院和《战争机器4》（GoW4）开发组的 <a href="http://schedule.gdconf.com/session/gears-of-war-4-project-triton-pre-computed-environmental-wave-acoustics" target="_blank" rel="external">Project Triton</a>，即通过预先演算声波传播物理参数来辅助人工设计的环境声学效果方案。本次的演讲实际上是微软已启动六年之久系列研究的首次产品化成果。演讲幻灯片<a href="http://www.nikunjr.com/Projects/Triton/Triton-GDC2017.pptx" target="_blank" rel="external">已放出</a>。以下尝试稍加总结。</p>
<h3 id="成果"><a href="#成果" class="headerlink" title="成果"></a>成果</h3><p>这乍一看很学术范的技术主要是为了解决游戏环境声学设计中的一大痛点：传统设计方法依赖在游戏地图中手工标注或绘制声学区域，再挂接音频效果器来实现室内混响和声障／声笼效果；音频中间件如 Wwise 的效果器控制参数一般是够用的，但在游戏中手工标注的工作量巨大且容易出错，实际开发工期紧，很难打磨调优。</p>
<p>不巧，玩家极易通过生活经验察觉这类设计错误，后果严重，参见《刺客信条：大革命》中曾出现的<a href="http://forums.ubi.com/showthread.php/973716-AC-Unity-Sound-Bug-Forums" target="_blank" rel="external">全局 bug</a>。音频设计界早就希望能像物理渲染界一样自动化这个过程，为创意设计赢得时间。</p>
<p>演讲中放出的<em>最终</em>解决方案：</p>
<img src="/2017/03/13/GDC17-音频见闻（1）-空间音频-Spatial-Audio/sa-triton-game-integration.jpg" title="Triton 系统整合示意图">
<ul>
<li>离线预处理：在游戏地图中自动选取采样位置，对各个位置上的发声体-听者结对（emitter-listener pair）根据几何数据自动做 3D 声波传播模拟并生成原始声学数据库；</li>
<li>解析：从原始声学数据自动提炼出一组感知参数值：直达波能量、反射波能量、反射波衰减率（wetness）和混响衰减率；</li>
<li>接入音频中间件：运行时通过查询数据库获取感知参数值，用来控制 Wwise 中的声障／声笼滤波器和辅助总线上的混响效果器，产生实时互动的声学效果。</li>
</ul>
<p>用这种方法，设计师不再需要手动标注环境声学区域，可以专注于艺术效果设计，即通过感知参数来控制音频效果输出。结果不但错误少，且游戏中的实时性能也达到甚至优于项目初始要求。</p>
<p>一些细节：</p>
<ul>
<li>声障值和声笼值分别用初始能量（直达声比例）和反射能量来代表；</li>
<li>区分室外和室内情况，方法是通过在室外设置理想边界，并测量从玩家位置发声后能抵达这条边界的能量占总能量的比例来推算<em>室内-室外比</em>，以此来做到平滑过渡；</li>
<li>原始声学数据计算用 100 台机器需要约 4 小时计算时间，初始数据为 50 TB，做解析后降为 100 MB。</li>
</ul>
<h3 id="经历"><a href="#经历" class="headerlink" title="经历"></a>经历</h3><p>很多学术报告大概也就到此为止了，让一部分听众感觉高山仰止，另一部分不知所云。然而这次两位主讲人–微软研究院的 Nikunj Raghuvanshi 和 Coalition 工作室的 John Tennant –继续披露了研发和产品化的详细经过，以机器人领域的<a href="http://baike.baidu.com/item/恐怖谷理论" target="_blank" rel="external"><em>恐怖谷</em></a>现象为纲，讲述了从真实到艺术真实的探索（微信游戏音频群里尾巴老师语），体现了对基础研究和产品化过程深刻的理解，是演讲中我个人最喜欢的部分。</p>
<img src="/2017/03/13/GDC17-音频见闻（1）-空间音频-Spatial-Audio/sa-triton-uncanny-valley.jpg">
<p>从 2011 年的 V1.0 到 2014 年的 V2.0 直到最终版，项目经历了标准的恐怖谷历程：</p>
<ol>
<li>V1.0 中初尝预处理甜头后，发现一些问题亟待解决，比如区分室内外和消除混响效果中的浑浊；</li>
<li>于是寄希望于自动化和仿真路线，火力全开，将模型复杂化：从 FDN 混响换成卷积混响，声学数据因此变成冲激响应，在增加室外效果器组分支的同时还增加了对早期反射和后期混响的区分，导致要控制 12 个混响单元；</li>
<li>不幸跌入恐怖谷，为了自救而后退一步，着重解决艺术真实问题，最后简化了模型，按时保质完成了产品化。</li>
</ol>
<p>一些真实和艺术真实的折衷处理：</p>
<ul>
<li>冲激响应路线很难控制质量：录音和测量人员不同，因此高度依赖配准，为后期调试带来困难，终弃；</li>
<li>混响效果受输入声音动态范围影响，将输入的<em>真实</em>动态范围做了艺术限制之后，清晰度得到提升；</li>
<li>与传统影视建立的艺术效果标准相比，物理计算中得出的直达声能量以及衰减时间，结合游戏具体玩法后，会出现不合心理期望的情况，终弃。</li>
</ul>
<p>有意思的是，上面的道理很多其实是马后炮：是在主动作出简化混响模型的决定后从实践中领悟到的，又一次说明奥卡姆剃刀原则的普适性。</p>
<h3 id="未来"><a href="#未来" class="headerlink" title="未来"></a>未来</h3><p>Triton 项目的未来计划包括在预处理模型中加入：</p>
<ul>
<li>直达分量方向性、早期反射、户外回声；</li>
<li>动态几何结构，比如活动的门窗和物理毁坏。</li>
</ul>
<p>巧的是，Triton 和 Wwise 不谋而合，这几条正是 GDC17 上 Wwise 2017.1 版本展出的新 Spatial Audio 功能的一部分，请看下篇。</p>
<h3 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h3><ul>
<li>演讲幻灯片: <a href="http://www.nikunjr.com/Projects/Triton/Triton-GDC2017.pptx" target="_blank" rel="external">‘Gears of War 4’, Project Triton: Pre-Computed Environmental Wave Acoustics</a></li>
<li>Engadget 文章：<a href="https://www.engadget.com/2016/10/25/gears-of-war-4-microsoft-research-triton/" target="_blank" rel="external">Microsoft Research helped ‘Gears of War 4’ sound so good</a></li>
<li>Triton V1.0 论文：<a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/10/6.pdf" target="_blank" rel="external">Raghuvanshi, et. al., SIGGRAPH 2010, “Precomputed wave simulation for real-time sound propagation of dynamic sources in complex scenes”
</a></li>
<li>Triton V2.0 论文：<a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/07/ParametricWaveField.pdf" target="_blank" rel="external">Raghuvanshi &amp; Snyder, SIGGRAPH 2014, “Parametric wave field coding for precomputed sound propagation”
</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;《Gears-of-War-4》中的环境声学预处理技术&quot;&gt;&lt;a href=&quot;#《Gears-of-War-4》中的环境声学预处理技术&quot; class=&quot;headerlink&quot; title=&quot;《Gears of War 4》中的环境声学预处理技术&quot;&gt;&lt;/a&gt;《Gear
    
    </summary>
    
      <category term="GameAudio" scheme="http://kakyoism.github.io/categories/GameAudio/"/>
    
    
      <category term="conference, gdc17, reverb, obstruction-occlusion, spatialaudio" scheme="http://kakyoism.github.io/tags/conference-gdc17-reverb-obstruction-occlusion-spatialaudio/"/>
    
  </entry>
  
  <entry>
    <title>补记 MIGS 2016 上的演讲见闻</title>
    <link href="http://kakyoism.github.io/2017/01/15/migs-2016/"/>
    <id>http://kakyoism.github.io/2017/01/15/migs-2016/</id>
    <published>2017-01-15T11:52:13.000Z</published>
    <updated>2017-05-02T00:32:24.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近一次的<a href="http://www.migs16.com/en/" target="_blank" rel="external">蒙特利尔国际游戏峰会 MIGS 2016</a>过去一阵子了，只有3岁的 MIGS 在规模上无法跟 GDC 这样的老字号相提并论，不过每年还是有些有用的技术演讲，在此追记一下自己去过那几场的要点，主要是音频专场。<a id="more"></a></p>
<img src="/2017/01/15/migs-2016/migs16-01.jpg">
<h2 id="Leonard-Paul-“用-Pure-Data-为游戏实现-Procedural-Audio”"><a href="#Leonard-Paul-“用-Pure-Data-为游戏实现-Procedural-Audio”" class="headerlink" title="Leonard Paul “用 Pure Data 为游戏实现 Procedural Audio”"></a><a href="http://www.migs16.com/en/events/procedural-game-audio-with-pure-data/" target="_blank" rel="external">Leonard Paul “用 Pure Data 为游戏实现 Procedural Audio”</a></h2><img src="/2017/01/15/migs-2016/migs16-02.jpg">
<p>音频设计师和教师 <a href="http://www.migs16.com/en/leonard-j-paul-2/" target="_blank" rel="external">Leonard Paul</a> 以 <a href="https://unity3d.com/learn/tutorials/projects/tanks-tutorial" target="_blank" rel="external">Unity 示例游戏</a>作为蓝本介绍了用 Pure Data（PD）实现 procedural audio（下称 PA）音频设计一些可能性。会后他还发布了这次演讲的<a href="https://t.co/7ay9kxzhOV" target="_blank" rel="external">幻灯</a>和<a href="https://t.co/7s0o9Xhoiy" target="_blank" rel="external">录音</a>。</p>
<p>在这个例子中 Leonard 展示了几个 PD patch。通过自己设计实现从 PD 到 Unity 的一整套 OSC（Open Sound Control）消息服务机制，建立了一条简单的音频原型迭代的管线：在 PD 中创建和修改设计，在 Unity 中测试，两端通过 OSC 沟通来试听和调整混音等。演示的声音大多采用简单的加法／减法／模态（Modal）实时合成方法，坦克碰撞声采用了 <a href="https://en.wikipedia.org/wiki/Karplus–Strong_string_synthesis" target="_blank" rel="external">Karplus-Strong</a> 算法。</p>
<p>关于 PD 生态的现状，Leonard 说 <a href="https://github.com/libpd/libpd" target="_blank" rel="external">libpd</a> 的性能还达不到游戏要求的实时性，但 <a href="https://enzienaudio.com" target="_blank" rel="external">Enzien Audio</a> 的 Heavy 系统的性能很有希望。目前 Heavy 支持大部分 PD 的对象，只有极少数关键对象比如 <a href="http://yadegari.org/expr/expr.html" target="_blank" rel="external">expr～</a> 不支持。</p>
<p>Leonard 也表示在游戏项目中选用 PD 这样的系统有一些注意事项：</p>
<ul>
<li>不应该为 PA 而 PA。从审美上不是所有的游戏都适合 PA，演讲采用的坦克游戏碰巧是美式动漫风，所以适合用常用的合成技术表现；</li>
<li>用 PD “做出声音”只是音频设计流程中的一方面，走这条路还需要自己实现通信协议、混音器、voice 控制，性能优化这些一般中间件里有的东西；</li>
<li>同一个功能可能有不同品质和性能代价的算法实现，可以考虑根据实时性能的波动切换算法以达到最优性价比；</li>
<li>在条件允许下，比如大公司和大型项目中一般还是以中间件为出发点。</li>
</ul>
<p><strong>感想：</strong>利用创意编程工具实现 PA 目前还是一个技术性很强的领域，Leonard 自我介绍时强调自己的编程背景并已经有 20 多年使用 Max（90 年代初还没有 MSP）和 PD 的经验也侧面佐证了这一点。</p>
<h2 id="RJ-Mattingly-“手工打造游戏音频利器”"><a href="#RJ-Mattingly-“手工打造游戏音频利器”" class="headerlink" title="RJ Mattingly “手工打造游戏音频利器”"></a><a href="http://www.migs16.com/en/events/making-the-sharpest/" target="_blank" rel="external">RJ Mattingly “手工打造游戏音频利器”</a></h2><img src="/2017/01/15/migs-2016/migs16-03.jpg">
<p><a href="http://www.migs16.com/en/rj-mattingly-2/" target="_blank" rel="external">RJ Mattingly</a> 是 PopCap 的技术声音设计师。PopCap 现在全面采用 Unity + Wwise 的音频开发流程，在演讲中他介绍了为优化 PopCap 内部工作流程写的一些小脚本工具，基本都用 Python 语言实现。</p>
<h3 id="SoundBank-管线工具"><a href="#SoundBank-管线工具" class="headerlink" title="SoundBank 管线工具"></a>SoundBank 管线工具</h3><p>PopCap 的 SoundBank 处理管线见上图。</p>
<p>他们早期基于 Perforce 的流程中声音设计师不但提交 Wwise 工程文件，还提交 SoundBank。这样一来因为 SoundBank 是团队共享的，所以容易出现冲突。RJ 的第一个显而易见的改进便是规定设计师不提交 SoundBank（设计产物），而只提交工程文件（设计本身），并在 <a href="https://jenkins.io" target="_blank" rel="external">Jenkins</a> 管线中通过脚本使用 Wwise 自带的命令行工具 <a href="https://www.audiokinetic.com/library/edge/?source=SDK&amp;id=bankscommandline.html" target="_blank" rel="external">WwiseCli</a> 生成项目的唯一一份 SoundBank，解决了冲突问题。</p>
<p>一个常见的人为错误是在生成 SoundBank 时漏加了文件或者多个 SoundBank 中有重复的音频源文件，这些错误有时几个礼拜之后才会发现。于是 RJ 利用 Wwise 中 SoundBank 生成的后处理 <a href="https://www.audiokinetic.com/library/edge/?source=Help&amp;id=defining_custom_user_steps_to_be_performed_pre_post_soundbank_generation" target="_blank" rel="external">post-generation step</a> 写了一个脚本来分析 Wwise 自动生成的日志，找到与缺少和重复文件相关的信息，并自动群发邮件。这样一来，错误一般都能当天发现并修正。</p>
<h3 id="Event-工具"><a href="#Event-工具" class="headerlink" title="Event 工具"></a>Event 工具</h3><p>在性能优化上，Wwise 中虽然有最大复音数限制机制，但有些时候项目会想从 Event 层面来做限制，比如三消游戏《Bejeweled》系列中的爆炸道具如不加限制会引爆上百个事件，目前 Wwise 中没有提供由设计师来指定事件数限制的流程。因为 Wwise 事件下有 Notes 这个属性，因为属性保存在事件所在的 WorkUnit（.wwu）文件中，RJ 于是把 Notes 当作特殊字段来用，写了一个脚本工具在 Notes 中加入自定义的事件限制文本编码，设计师可以在 Wwise 中进一步手动调整，然后工具会分析 .wwu 并生成游戏程序可以读取的 metadata 作为事件限制的参考数据。</p>
<h3 id="动画配声工具"><a href="#动画配声工具" class="headerlink" title="动画配声工具"></a>动画配声工具</h3><p>在《Plants vs. Zombies: Heroes》中有 300 多个角色，每个角色有 5-20 个动画序列，所以手工配声工作量巨大。于是 RJ 写了一个 Unity UI 拓展能够改进这个流程，并能够自动比较 Unity 端登记的动画 Event 和 Wwise 设计工具端的 Event，保证在 Unity 端登记的 Wwise Event 确实存在。</p>
<p>设计师往往喜欢把 Unity 的动画导出成视频文件然后到 DAW 中配声，但 Unity 没有这种导出支持。于是 RJ 写了工具自动导出动画成视频，方法是：将动画帧自动截屏成图片，再用 <a href="https://ffmpeg.org" target="_blank" rel="external">ffmpeg</a> 的命令行工具将这些图片批量组装成视频文件。</p>
<h2 id="Benoit-Alary-“用于虚拟声学空间的沉浸式混响”"><a href="#Benoit-Alary-“用于虚拟声学空间的沉浸式混响”" class="headerlink" title="Benoit Alary “用于虚拟声学空间的沉浸式混响”"></a><a href="http://www.migs16.com/en/blog/events/immersive-reverberation/" target="_blank" rel="external">Benoit Alary “用于虚拟声学空间的沉浸式混响”</a></h2><p>Audiokinetic 的 Benoit Alary 做了关于 Audiokinetic 研发的新互动混响插件（代号 <em>SynthSpace</em>）的演讲，作为早先<a href="https://blog.audiokinetic.com/migs/" target="_blank" rel="external">这篇博客</a>的展开并演示了原型效果。</p>
<p>传统混响技术有其局限性。参数混响比如 <a href="https://ccrma.stanford.edu/~jos/pasp/FDN_Reverberation.html" target="_blank" rel="external">FDN 算法族</a> 难以加入逼真的互动效果，比如玩家在室内走动时，很难根据玩家离墙的远近自动调整早期反射效果。而在其它方面相对参数混响有优势的卷积混响如果想要克服这一点，则需要录制多个冲激响应（IR）来捕捉整个空间。暴雪在《Overwatch》中为了改进这点研发了自己的内部 Wwise 插件 Quad Delay 用来加入与环境互动的反射效果，见他们的 <a href="http://gdcvault.com/play/1023010/Overwatch-The-Elusive-Goal-Play" target="_blank" rel="external">GDC 2016 演讲</a>。</p>
<p>以往在解决这个问题上有两派：</p>
<ul>
<li>几何方法：将混响问题中的声音传播退化为类几何光学问题，研究从声源出发的理想射线在封闭空间中的几何反射。但这种简化做法不考虑声波的干涉等性质，如果用于整个混响过程，则效果有局限。</li>
<li>波方法：直接模拟声波传播，考虑所有波的性质包括干涉。这种做法运算量巨大，目前唯一实际的做法是离线计算好各种参数并储存为数据库供应用程序实时检索使用，但对设计流程来说离线计算的开销可能就是小时甚至天的数量级。另一个问题是，波方法需要每秒 4 万次以上的反射取样，因此在数字音频采样率的限制下对高频的表现不会很好。</li>
</ul>
<p>在游戏等媒体应用中，实际需求往往并不是完全逼真地模拟现实中的混响，而是需要给音频设计师足够的控制来达到某种艺术效果。</p>
<p>目前的趋势是混成混响（Hybrid Reverb）技术：拆分混响过程，利用几何方法来控制早期反射（early reflection），而用传统混响来控制后期混响（late reverb）。</p>
<p><em>SynthSpace</em> 的这款 Wwise 混音器插件就是给高品质混响用户群特别是 VR／AR 项目准备的实用工具。</p>
<img src="/2017/01/15/migs-2016/migs16-04.JPG">
<img src="/2017/01/15/migs-2016/migs16-05.JPG">
<p>它的用法是在一条混响总线上加入此插件，实时接收游戏发送的空间鞋盒（shoebox）模型以及发声体和听者在空间中的位置，基于这些数据进行实时反射计算，取代参数混响中的 Pre-Delay 参数，设计师可以在 Wwise 中对反射等效果和性能需求做精确的设计，再结合其它混响效果实现完整的互动混响。《Overwatch》的 Quad Delay 插件是基于 4 个平面方向的环绕声方案，相比之下，<em>SynthSpace</em> 支持 6 个方向的三维空间，因而也支持 spatial audio，在传统游戏和 VR/AR 中都有用武之地。</p>
<p>演示用到了 Wwise 后续将发布的全新 3D 测试游戏地图，将作为 Cube Demo 基础上更适合测试声学效果的 demo 安装包。<em>SynthSpace</em> 将于 2017 年内面世，到时候可能会有正式的新名字。</p>
<h2 id="Olivier-Deriviere-“环境音乐，互动配乐的下一步-”"><a href="#Olivier-Deriviere-“环境音乐，互动配乐的下一步-”" class="headerlink" title="Olivier Deriviere “环境音乐，互动配乐的下一步?”"></a><a href="http://www.migs16.com/en/blog/events/environmental-music/" target="_blank" rel="external">Olivier Deriviere “环境音乐，互动配乐的下一步?”</a></h2><p><a href="http://olivierderiviere.com" target="_blank" rel="external">Olivier Deriviere</a> 之前在 <a href="https://www.youtube.com/watch?v=kWyf90LXLAg" target="_blank" rel="external">《Remember Me》（2013）</a> 中将战斗音乐的互动性推到了新高度，这次他介绍了在万代南梦宫新作<a href="https://www.youtube.com/watch?v=E9qQz0X7QYM" target="_blank" rel="external">《Get Even》</a>中的新实验：利用 Wwise 和 3D Audio 将环境声和音乐融为一体。之前在《DOOM》（2016）中已嗅到这种味道。这场据说是这届 MIGS 上最值得去的音频演讲，可惜没有去成，不过游戏在 GDC 2017 上会有首秀，很期待。</p>
<h2 id="Wolff-Dobson-“机器学习、游戏和你”"><a href="#Wolff-Dobson-“机器学习、游戏和你”" class="headerlink" title="Wolff Dobson “机器学习、游戏和你”"></a><a href="http://www.migs16.com/en/blog/events/machine-learning-games-and-you/" target="_blank" rel="external">Wolff Dobson “机器学习、游戏和你”</a></h2><p>这是去的唯一一场非音频演讲。来自 Google 机器学习组的 <a href="http://www.migs16.com/en/blog/2016/10/16/wolff-dobson-2/" target="_blank" rel="external">Wolff Dobson</a>这场大半是科普机器学习特别是深度学习及其新进展，也指出了游戏中机器学习的一些应用的可能性和已经用到的场合：</p>
<ul>
<li>分析玩家的入坑、内购、弃坑规律，在预测到可能行为时推送合适的内容促进留存率；</li>
<li>分析游戏中玩家聊天记录判断情绪；</li>
<li>分析监测作弊行为；</li>
<li>分析玩家的玩法特征，让游戏内容作出适配；</li>
<li>分析电影中的真人动作和物理系统来自动生成游戏物理系统和动画；</li>
<li>分析玩家的操作和策略，利用<a href="http://baike.baidu.com/view/1627904.htm" target="_blank" rel="external">强化学习</a>给玩家策略建议；</li>
<li>分析生物面部特征，做出更自动化的捏脸系统；</li>
<li>自动生成内容：关卡、对白、NPC。</li>
</ul>
<p>他也强调“玩家的乐趣”是终极目标，而不是为了机器学习而学习。比如，在角色扮演和第一人称游戏里面玩家的视野和注意力受限，所以镜头外的 AI 其实必要性不大，因为玩家要么注意不到，要么可能把 NPC 在 GPS 上的“出色”表现理解为是机器作弊。</p>
<p>他也提到了一些游戏以外的机器学习应用：</p>
<p><img src="https://github.com/david-gpu/srez/raw/master/srez_sample_output.png" alt=""></p>
<p><a href="https://github.com/david-gpu/srez" target="_blank" rel="external">图片低清转高清</a></p>
<img src="/2017/01/15/migs-2016/migs16-06.png">
<p><a href="https://www.youtube.com/watch?v=6ZHiARZmiUI" target="_blank" rel="external">实时混合油画滤镜</a></p>
<p><img src="https://github.com/Newmu/dcgan_code/blob/master/images/lsun_bedrooms_five_epoch_samples.png?raw=true" alt=""></p>
<p><img src="https://github.com/Newmu/dcgan_code/blob/master/images/albums_128px.png?raw=true" alt=""><br><a href="https://github.com/Newmu/dcgan_code" target="_blank" rel="external">自动生成卧室照片、唱片封套</a>（之前我在朋友圈转过）</p>
<p><img src="https://tctechcrunch2011.files.wordpress.com/2016/09/trash2.jpg?w=738" alt=""></p>
<p><a href="https://techcrunch.com/2016/09/13/auto-trash-sorts-garbage-automatically-at-the-techcrunch-disrupt-hackathon/" target="_blank" rel="external">自动垃圾分类</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近一次的&lt;a href=&quot;http://www.migs16.com/en/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;蒙特利尔国际游戏峰会 MIGS 2016&lt;/a&gt;过去一阵子了，只有3岁的 MIGS 在规模上无法跟 GDC 这样的老字号相提并论，不过每年还是有些有用的技术演讲，在此追记一下自己去过那几场的要点，主要是音频专场。
    
    </summary>
    
      <category term="GameAudio" scheme="http://kakyoism.github.io/categories/GameAudio/"/>
    
    
      <category term="wwise" scheme="http://kakyoism.github.io/tags/wwise/"/>
    
      <category term="conference" scheme="http://kakyoism.github.io/tags/conference/"/>
    
      <category term="proceduralaudio" scheme="http://kakyoism.github.io/tags/proceduralaudio/"/>
    
      <category term="reverb" scheme="http://kakyoism.github.io/tags/reverb/"/>
    
      <category term="machinelearning" scheme="http://kakyoism.github.io/tags/machinelearning/"/>
    
  </entry>
  
  <entry>
    <title>第一天</title>
    <link href="http://kakyoism.github.io/2016/12/25/Hello-Hexo-%E4%BD%A0%E5%A5%BD-Hexo/"/>
    <id>http://kakyoism.github.io/2016/12/25/Hello-Hexo-你好-Hexo/</id>
    <published>2016-12-25T05:54:17.000Z</published>
    <updated>2017-05-02T00:32:24.000Z</updated>
    
    <content type="html"><![CDATA[<p>之前玩公众号，但发现在引用外链和离线写作方面有限制。很多时候我期待的是自由外链引用、离线为主、一键发布、迭代迁移方便的博客流程。</p>
<p>GitHub 的静态站点系统 <a href="https://pages.github.com" target="_blank" rel="external">GitHub Pages</a> 支持按照软件开发流程来管理博客，通过纯文本标记格式比如 <a href="https://en.wikipedia.org/wiki/Markdown" target="_blank" rel="external">Markdown</a> 写作存为本地文件，再一键发布到远程。</p>
<p>所以来 GitHub 试试。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;之前玩公众号，但发现在引用外链和离线写作方面有限制。很多时候我期待的是自由外链引用、离线为主、一键发布、迭代迁移方便的博客流程。&lt;/p&gt;
&lt;p&gt;GitHub 的静态站点系统 &lt;a href=&quot;https://pages.github.com&quot; target=&quot;_blank&quot;
    
    </summary>
    
      <category term="Writing" scheme="http://kakyoism.github.io/categories/Writing/"/>
    
    
      <category term="github" scheme="http://kakyoism.github.io/tags/github/"/>
    
  </entry>
  
</feed>
